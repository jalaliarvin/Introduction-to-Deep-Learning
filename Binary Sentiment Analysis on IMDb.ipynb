{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TurkuNLP/intro-to-nlp/blob/master/course_project_2023_template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucyWlC5gbOyR"
      },
      "source": [
        "# Introduction to HLT Project (Template)\n",
        "\n",
        "- Student Name: Arvin Jalali\n",
        "- Date: 22 August 2024\n",
        "- Chosen Corpus: imdb\n",
        "- Contributions (if group project): no\n",
        "- Please note that I declare that I have used ChatGPT in various ways during this project. However, my usage was critical and not unreflective.\n",
        "\n",
        "### Corpus information\n",
        "\n",
        "- Description of the chosen corpus:\n",
        "Large Movie Review Dataset. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
        "\n",
        "- Paper(s) and other published materials related to the corpus: There are several papers that are quite good for understanding binary sentiment analysis on the IMDb corpus using different machine learning methods. Below, I list a few of them that are considered to be good reads for beginners. The second paper is particularly good for understanding the key concepts and details. However, I must confess that, in addition to the papers, ChatGPT is also very informative.\n",
        "\n",
        "- \"Machine Learning-Based Classification for Sentiment Analysis of IMDb Reviews\" by Chun-Liang Wu and Song-Ling Shin, Stanford University.\n",
        "\n",
        "- \"Sentiment Analysis on IMDb Using Lexicon and Neural Networks\" by Zeeshan Shaukat, Abdul Ahad Zulfiqar, Chuangbai Xiao, Muhammad Azeem, and Tariq Mahmood.\n",
        "\n",
        "- State-of-the-art performance (best published results) on this corpus:\n",
        "The state-of-the-art performance for IMDb binary sentiment analysis is achieved by the RoBERTa-large with LlamBERT model, reaching an accuracy of 96.68%, leveraging large-scale low-cost data annotation in NLP.\n",
        "https://paperswithcode.com/sota/sentiment-analysis-on-imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5d-9uxrcDY-"
      },
      "source": [
        "---\n",
        "\n",
        "## 1. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "caHHQoqEcG1J"
      },
      "outputs": [],
      "source": [
        "# Install necessary libraries quietly\n",
        "!pip install --quiet torch transformers datasets evaluate accelerate\n",
        "\n",
        "# Import essential libraries for NLP and data handling\n",
        "import numpy as np  # For numerical operations\n",
        "import datasets  # For handling datasets\n",
        "from datasets import load_dataset, load_metric  # For loading datasets and metrics\n",
        "import transformers  # For pre-trained transformer models\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BertConfig, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "import evaluate  # For evaluation utilities\n",
        "from sklearn.metrics import accuracy_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovUapilSb8iT"
      },
      "source": [
        "---\n",
        "\n",
        "## 2. Data download and preprocessing\n",
        "\n",
        "### 2.1. Download the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PDx40YyzbGPc"
      },
      "outputs": [],
      "source": [
        "# Your code to download the corpus here\n",
        "\n",
        "# Define the name of the dataset to load\n",
        "DATASET = 'imdb'\n",
        "\n",
        "# Load the dataset builder for the specified dataset\n",
        "# The builder is responsible for preparing and configuring the dataset\n",
        "builder = datasets.load_dataset_builder(DATASET)\n",
        "\n",
        "# Load the dataset itself into memory\n",
        "# This will download and prepare the dataset for use\n",
        "dataset = datasets.load_dataset(DATASET)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXb7CQNCbZOI"
      },
      "source": [
        "### 2.2. Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e2def51556034a1599e7f2f89adbd534",
            "b6884a3d87ba4770abb7ead9288dd36e",
            "876482b203ea456dbbd565b7b39d2e35",
            "bc848861549d47a68fbee496e89a0998",
            "ff8f9d056a504a44a78c25af6fa42fa8",
            "ff10836ee2ef439bb5dbe6d279623d8b",
            "90ef87fe5d324877bdfe5c35014b1539",
            "354c266c96d848d79e736022dc5c0cdb",
            "f37228fed04445908f47de9d6a757fbd",
            "624b2097c25b44e39f5033852d764c8d",
            "d067162df7d244e98240db8f934ea10b"
          ]
        },
        "id": "RO5BXCuRbYKr",
        "outputId": "3bc717f2-d60a-439c-c797-528695e0d191"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2500 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e2def51556034a1599e7f2f89adbd534"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "# Load the full dataset\n",
        "dataset = load_dataset('imdb')\n",
        "\n",
        "# Split the dataset into train, validation, and test sets\n",
        "# Here we split the original train set into train and validation sets\n",
        "train_full = dataset['train']\n",
        "test = dataset['test']\n",
        "train, val = train_full.train_test_split(test_size=0.1, seed=42).values()\n",
        "\n",
        "# Define mappings for label IDs and labels\n",
        "id2label = {0: \"neg\", 1: \"pos\"}\n",
        "label2id = {\"neg\": 0, \"pos\": 1}\n",
        "\n",
        "# Specify the name of the pre-trained BERT model\n",
        "MODEL_NAME = \"bert-base-uncased\"\n",
        "\n",
        "# Load the tokenizer for the specified BERT model\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Load the pre-trained BERT model with the specified configuration\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    config=BertConfig(num_labels=2, id2label=id2label, label2id=label2id)\n",
        ")\n",
        "\n",
        "# Define a function to tokenize text examples\n",
        "def tokenize(example, tokenizer):\n",
        "    return tokenizer(example['text'], truncation=True, padding='max_length')\n",
        "\n",
        "# Apply tokenization to the training dataset\n",
        "train = train.map(lambda example: tokenize(example, tokenizer), batched=True)\n",
        "\n",
        "# Apply tokenization to the validation dataset\n",
        "val = val.map(lambda example: tokenize(example, tokenizer), batched=True)\n",
        "\n",
        "# Apply tokenization to the test dataset\n",
        "test = test.map(lambda example: tokenize(example, tokenizer), batched=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1ntHh_JbrAg"
      },
      "source": [
        "---\n",
        "\n",
        "## 3. Machine learning model\n",
        "\n",
        "### 3.1. Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "Hs2Bf49zbn5C",
        "outputId": "0d5fb434-9ff7-4461-87c1-2f77d1d6c4e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 13:10, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.554000</td>\n",
              "      <td>0.424969</td>\n",
              "      <td>0.837600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.372000</td>\n",
              "      <td>0.277872</td>\n",
              "      <td>0.890000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.346500</td>\n",
              "      <td>0.344154</td>\n",
              "      <td>0.893600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.284900</td>\n",
              "      <td>0.335111</td>\n",
              "      <td>0.902400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.311100</td>\n",
              "      <td>0.288250</td>\n",
              "      <td>0.906800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.37368193054199217, metrics={'train_runtime': 791.4928, 'train_samples_per_second': 5.054, 'train_steps_per_second': 0.632, 'total_flos': 1052444221440000.0, 'train_loss': 0.37368193054199217, 'epoch': 0.17774617845716317})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Your code to train the machine learning model on the training set and evaluate the performance on the validation set here\n",
        "\n",
        "# Define the metric to evaluate model performance\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Function to compute metrics from model predictions\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Convert logits to predicted class labels\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    # Compute accuracy using the loaded metric\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Prepare a data collator for dynamic padding of batches\n",
        "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Set up early stopping to halt training if no improvement is seen for a certain number of evaluations\n",
        "early_stopping_patience = 5\n",
        "early_stopping = transformers.EarlyStoppingCallback(early_stopping_patience)\n",
        "\n",
        "# Define training arguments and configuration\n",
        "trainer_args = transformers.TrainingArguments(\n",
        "    output_dir='checkpoints',                 # Directory to save model checkpoints\n",
        "    evaluation_strategy='steps',              # Evaluate model every few steps\n",
        "    logging_strategy='steps',                 # Log training progress every few steps\n",
        "    load_best_model_at_end=True,              # Load the best model based on validation performance at the end of training\n",
        "    eval_steps=100,                           # Number of steps between evaluations\n",
        "    logging_steps=100,                        # Number of steps between logging\n",
        "    learning_rate=0.00005,                    # Learning rate for the optimizer\n",
        "    per_device_train_batch_size=8,            # Batch size for training\n",
        "    per_device_eval_batch_size=32,            # Batch size for evaluation\n",
        "    max_steps=500,                            # Maximum number of training steps\n",
        ")\n",
        "\n",
        "# Initialize the model for sequence classification with pre-trained weights\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    config=BertConfig(num_labels=2, id2label=id2label, label2id=label2id)\n",
        ")\n",
        "\n",
        "# Set up the Trainer with the model, arguments, datasets, and evaluation function\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    args=trainer_args,\n",
        "    train_dataset=train,\n",
        "    eval_dataset=val,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlO8RVuHcmAh"
      },
      "source": [
        "### 3.2 Hyperparameter optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "abec4cfcd3594c49b226d9ec86f46d2c",
            "f28a7101070342839569776cb93b9792",
            "4004f150204e464db1166d7186ad206b",
            "6f23671e01f0482080514e219420de3e",
            "e4ec6dbae48f45d2affdd94e0e20f537",
            "bb164048af824fa1a43e16a44737bdd2",
            "babc45c1449f4fdc9a1302b7668ccacc",
            "488773a845f246228805bdab86a754ac",
            "8115fc4a046946929b7f70e2e9c5e97f",
            "439159668d464fcb8534597dcd6ce4e7",
            "489ddb48c07d4bf1ac929004d0a93175"
          ]
        },
        "id": "IzDrTDd0cWOG",
        "outputId": "6dd7ae39-3d45-4326-88b1-7f8802d7c1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-423e9fb11c88>:8: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  accuracy_metric = load_metric(\"accuracy\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abec4cfcd3594c49b226d9ec86f46d2c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The repository for accuracy contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/accuracy.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n",
            "Training with learning_rate=1e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.6071, 'grad_norm': 22.04717445373535, 'learning_rate': 9.644507643085674e-06, 'epoch': 0.03554923569143263}\n",
            "{'eval_loss': 0.39751434326171875, 'eval_accuracy': 0.8724, 'eval_runtime': 79.6334, 'eval_samples_per_second': 31.394, 'eval_steps_per_second': 0.992, 'epoch': 0.03554923569143263}\n",
            "{'loss': 0.3551, 'grad_norm': 1.8306313753128052, 'learning_rate': 9.289015286171348e-06, 'epoch': 0.07109847138286526}\n",
            "{'eval_loss': 0.28923749923706055, 'eval_accuracy': 0.8884, 'eval_runtime': 78.7593, 'eval_samples_per_second': 31.742, 'eval_steps_per_second': 1.003, 'epoch': 0.07109847138286526}\n",
            "{'loss': 0.3233, 'grad_norm': 15.086372375488281, 'learning_rate': 8.933522929257021e-06, 'epoch': 0.10664770707429791}\n",
            "{'eval_loss': 0.35335102677345276, 'eval_accuracy': 0.89, 'eval_runtime': 78.4014, 'eval_samples_per_second': 31.887, 'eval_steps_per_second': 1.008, 'epoch': 0.10664770707429791}\n",
            "{'loss': 0.3124, 'grad_norm': 0.6667317152023315, 'learning_rate': 8.578030572342695e-06, 'epoch': 0.14219694276573053}\n",
            "{'eval_loss': 0.34018638730049133, 'eval_accuracy': 0.898, 'eval_runtime': 78.4921, 'eval_samples_per_second': 31.85, 'eval_steps_per_second': 1.006, 'epoch': 0.14219694276573053}\n",
            "{'loss': 0.3532, 'grad_norm': 0.5047647953033447, 'learning_rate': 8.22253821542837e-06, 'epoch': 0.17774617845716317}\n",
            "{'eval_loss': 0.2876376509666443, 'eval_accuracy': 0.9052, 'eval_runtime': 78.4839, 'eval_samples_per_second': 31.854, 'eval_steps_per_second': 1.007, 'epoch': 0.17774617845716317}\n",
            "{'loss': 0.3499, 'grad_norm': 12.65999984741211, 'learning_rate': 7.867045858514043e-06, 'epoch': 0.21329541414859582}\n",
            "{'eval_loss': 0.3011651337146759, 'eval_accuracy': 0.9024, 'eval_runtime': 78.8698, 'eval_samples_per_second': 31.698, 'eval_steps_per_second': 1.002, 'epoch': 0.21329541414859582}\n",
            "{'loss': 0.2774, 'grad_norm': 16.876394271850586, 'learning_rate': 7.511553501599716e-06, 'epoch': 0.24884464984002844}\n",
            "{'eval_loss': 0.31468990445137024, 'eval_accuracy': 0.9004, 'eval_runtime': 78.7125, 'eval_samples_per_second': 31.761, 'eval_steps_per_second': 1.004, 'epoch': 0.24884464984002844}\n",
            "{'loss': 0.3008, 'grad_norm': 21.368045806884766, 'learning_rate': 7.15606114468539e-06, 'epoch': 0.28439388553146105}\n",
            "{'eval_loss': 0.28856879472732544, 'eval_accuracy': 0.9112, 'eval_runtime': 78.9224, 'eval_samples_per_second': 31.677, 'eval_steps_per_second': 1.001, 'epoch': 0.28439388553146105}\n",
            "{'loss': 0.3306, 'grad_norm': 2.6086459159851074, 'learning_rate': 6.8005687877710635e-06, 'epoch': 0.3199431212228937}\n",
            "{'eval_loss': 0.2573537528514862, 'eval_accuracy': 0.908, 'eval_runtime': 78.5155, 'eval_samples_per_second': 31.841, 'eval_steps_per_second': 1.006, 'epoch': 0.3199431212228937}\n",
            "{'loss': 0.2436, 'grad_norm': 38.054359436035156, 'learning_rate': 6.445076430856737e-06, 'epoch': 0.35549235691432635}\n",
            "{'eval_loss': 0.2915121018886566, 'eval_accuracy': 0.9168, 'eval_runtime': 78.8079, 'eval_samples_per_second': 31.723, 'eval_steps_per_second': 1.002, 'epoch': 0.35549235691432635}\n",
            "{'loss': 0.2339, 'grad_norm': 17.318422317504883, 'learning_rate': 6.089584073942411e-06, 'epoch': 0.391041592605759}\n",
            "{'eval_loss': 0.26317811012268066, 'eval_accuracy': 0.9164, 'eval_runtime': 78.9953, 'eval_samples_per_second': 31.647, 'eval_steps_per_second': 1.0, 'epoch': 0.391041592605759}\n",
            "{'loss': 0.2632, 'grad_norm': 3.260714530944824, 'learning_rate': 5.7340917170280844e-06, 'epoch': 0.42659082829719164}\n",
            "{'eval_loss': 0.3036636710166931, 'eval_accuracy': 0.9212, 'eval_runtime': 78.7943, 'eval_samples_per_second': 31.728, 'eval_steps_per_second': 1.003, 'epoch': 0.42659082829719164}\n",
            "{'loss': 0.2706, 'grad_norm': 15.750998497009277, 'learning_rate': 5.378599360113757e-06, 'epoch': 0.46214006398862423}\n",
            "{'eval_loss': 0.268277108669281, 'eval_accuracy': 0.9204, 'eval_runtime': 78.9284, 'eval_samples_per_second': 31.674, 'eval_steps_per_second': 1.001, 'epoch': 0.46214006398862423}\n",
            "{'loss': 0.2445, 'grad_norm': 12.732741355895996, 'learning_rate': 5.023107003199431e-06, 'epoch': 0.4976892996800569}\n",
            "{'eval_loss': 0.2918158173561096, 'eval_accuracy': 0.9244, 'eval_runtime': 79.0064, 'eval_samples_per_second': 31.643, 'eval_steps_per_second': 1.0, 'epoch': 0.4976892996800569}\n",
            "{'loss': 0.308, 'grad_norm': 21.84619140625, 'learning_rate': 4.667614646285105e-06, 'epoch': 0.5332385353714895}\n",
            "{'eval_loss': 0.26616916060447693, 'eval_accuracy': 0.9176, 'eval_runtime': 78.448, 'eval_samples_per_second': 31.868, 'eval_steps_per_second': 1.007, 'epoch': 0.5332385353714895}\n",
            "{'loss': 0.2017, 'grad_norm': 28.758010864257812, 'learning_rate': 4.312122289370779e-06, 'epoch': 0.5687877710629221}\n",
            "{'eval_loss': 0.2886179983615875, 'eval_accuracy': 0.9212, 'eval_runtime': 78.8727, 'eval_samples_per_second': 31.697, 'eval_steps_per_second': 1.002, 'epoch': 0.5687877710629221}\n",
            "{'loss': 0.2468, 'grad_norm': 5.04195499420166, 'learning_rate': 3.956629932456453e-06, 'epoch': 0.6043370067543548}\n",
            "{'eval_loss': 0.3181608319282532, 'eval_accuracy': 0.9204, 'eval_runtime': 78.6254, 'eval_samples_per_second': 31.796, 'eval_steps_per_second': 1.005, 'epoch': 0.6043370067543548}\n",
            "{'loss': 0.2242, 'grad_norm': 10.245034217834473, 'learning_rate': 3.6011375755421262e-06, 'epoch': 0.6398862424457874}\n",
            "{'eval_loss': 0.30142948031425476, 'eval_accuracy': 0.9212, 'eval_runtime': 78.9171, 'eval_samples_per_second': 31.679, 'eval_steps_per_second': 1.001, 'epoch': 0.6398862424457874}\n",
            "{'loss': 0.2806, 'grad_norm': 2.303152322769165, 'learning_rate': 3.2456452186278e-06, 'epoch': 0.67543547813722}\n",
            "{'eval_loss': 0.2823043465614319, 'eval_accuracy': 0.9216, 'eval_runtime': 78.8095, 'eval_samples_per_second': 31.722, 'eval_steps_per_second': 1.002, 'epoch': 0.67543547813722}\n",
            "{'loss': 0.2682, 'grad_norm': 15.341482162475586, 'learning_rate': 2.8901528617134735e-06, 'epoch': 0.7109847138286527}\n",
            "{'eval_loss': 0.27991563081741333, 'eval_accuracy': 0.92, 'eval_runtime': 78.5796, 'eval_samples_per_second': 31.815, 'eval_steps_per_second': 1.005, 'epoch': 0.7109847138286527}\n",
            "{'loss': 0.2532, 'grad_norm': 0.3133118748664856, 'learning_rate': 2.5346605047991467e-06, 'epoch': 0.7465339495200853}\n",
            "{'eval_loss': 0.267609566450119, 'eval_accuracy': 0.926, 'eval_runtime': 78.7819, 'eval_samples_per_second': 31.733, 'eval_steps_per_second': 1.003, 'epoch': 0.7465339495200853}\n",
            "{'loss': 0.2588, 'grad_norm': 0.300985187292099, 'learning_rate': 2.1791681478848208e-06, 'epoch': 0.782083185211518}\n",
            "{'eval_loss': 0.27895045280456543, 'eval_accuracy': 0.9244, 'eval_runtime': 78.9658, 'eval_samples_per_second': 31.659, 'eval_steps_per_second': 1.0, 'epoch': 0.782083185211518}\n",
            "{'loss': 0.2468, 'grad_norm': 23.00356674194336, 'learning_rate': 1.8236757909704944e-06, 'epoch': 0.8176324209029506}\n",
            "{'eval_loss': 0.26283782720565796, 'eval_accuracy': 0.9272, 'eval_runtime': 78.9972, 'eval_samples_per_second': 31.647, 'eval_steps_per_second': 1.0, 'epoch': 0.8176324209029506}\n",
            "{'loss': 0.304, 'grad_norm': 1.004411220550537, 'learning_rate': 1.4681834340561678e-06, 'epoch': 0.8531816565943833}\n",
            "{'eval_loss': 0.2421545386314392, 'eval_accuracy': 0.9256, 'eval_runtime': 78.4642, 'eval_samples_per_second': 31.862, 'eval_steps_per_second': 1.007, 'epoch': 0.8531816565943833}\n",
            "{'loss': 0.2325, 'grad_norm': 27.165807723999023, 'learning_rate': 1.1126910771418415e-06, 'epoch': 0.8887308922858158}\n",
            "{'eval_loss': 0.2466018795967102, 'eval_accuracy': 0.9276, 'eval_runtime': 78.4358, 'eval_samples_per_second': 31.873, 'eval_steps_per_second': 1.007, 'epoch': 0.8887308922858158}\n",
            "{'loss': 0.2912, 'grad_norm': 17.485960006713867, 'learning_rate': 7.571987202275152e-07, 'epoch': 0.9242801279772485}\n",
            "{'eval_loss': 0.2512447237968445, 'eval_accuracy': 0.9264, 'eval_runtime': 78.7848, 'eval_samples_per_second': 31.732, 'eval_steps_per_second': 1.003, 'epoch': 0.9242801279772485}\n",
            "{'loss': 0.2431, 'grad_norm': 31.54690170288086, 'learning_rate': 4.017063633131888e-07, 'epoch': 0.9598293636686811}\n",
            "{'eval_loss': 0.2521580159664154, 'eval_accuracy': 0.9256, 'eval_runtime': 78.5018, 'eval_samples_per_second': 31.846, 'eval_steps_per_second': 1.006, 'epoch': 0.9598293636686811}\n",
            "{'loss': 0.2329, 'grad_norm': 46.2069091796875, 'learning_rate': 4.621400639886243e-08, 'epoch': 0.9953785993601137}\n",
            "{'eval_loss': 0.25416454672813416, 'eval_accuracy': 0.9268, 'eval_runtime': 78.4792, 'eval_samples_per_second': 31.856, 'eval_steps_per_second': 1.007, 'epoch': 0.9953785993601137}\n",
            "{'train_runtime': 4431.0552, 'train_samples_per_second': 5.078, 'train_steps_per_second': 0.635, 'train_loss': 0.28795924324011235, 'epoch': 1.0}\n",
            "{'eval_loss': 0.2466018795967102, 'eval_accuracy': 0.9276, 'eval_runtime': 79.1242, 'eval_samples_per_second': 31.596, 'eval_steps_per_second': 0.998, 'epoch': 1.0}\n",
            "Validation accuracy: 0.9276\n",
            "Training with learning_rate=3e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.5603, 'grad_norm': 9.016888618469238, 'learning_rate': 2.893352292925702e-05, 'epoch': 0.03554923569143263}\n",
            "{'eval_loss': 0.3524421751499176, 'eval_accuracy': 0.8636, 'eval_runtime': 78.5288, 'eval_samples_per_second': 31.835, 'eval_steps_per_second': 1.006, 'epoch': 0.03554923569143263}\n",
            "{'loss': 0.3583, 'grad_norm': 1.3554198741912842, 'learning_rate': 2.786704585851404e-05, 'epoch': 0.07109847138286526}\n",
            "{'eval_loss': 0.30092519521713257, 'eval_accuracy': 0.9016, 'eval_runtime': 78.2346, 'eval_samples_per_second': 31.955, 'eval_steps_per_second': 1.01, 'epoch': 0.07109847138286526}\n",
            "{'loss': 0.3652, 'grad_norm': 8.327018737792969, 'learning_rate': 2.680056878777106e-05, 'epoch': 0.10664770707429791}\n",
            "{'eval_loss': 0.3142629861831665, 'eval_accuracy': 0.8884, 'eval_runtime': 78.7468, 'eval_samples_per_second': 31.747, 'eval_steps_per_second': 1.003, 'epoch': 0.10664770707429791}\n",
            "{'loss': 0.3163, 'grad_norm': 0.6078668832778931, 'learning_rate': 2.5734091717028084e-05, 'epoch': 0.14219694276573053}\n",
            "{'eval_loss': 0.3647037446498871, 'eval_accuracy': 0.8964, 'eval_runtime': 78.5546, 'eval_samples_per_second': 31.825, 'eval_steps_per_second': 1.006, 'epoch': 0.14219694276573053}\n",
            "{'loss': 0.3358, 'grad_norm': 0.4853360056877136, 'learning_rate': 2.4667614646285108e-05, 'epoch': 0.17774617845716317}\n",
            "{'eval_loss': 0.27121758460998535, 'eval_accuracy': 0.9108, 'eval_runtime': 78.6993, 'eval_samples_per_second': 31.766, 'eval_steps_per_second': 1.004, 'epoch': 0.17774617845716317}\n",
            "{'loss': 0.3514, 'grad_norm': 57.99388122558594, 'learning_rate': 2.3601137575542128e-05, 'epoch': 0.21329541414859582}\n",
            "{'eval_loss': 0.34884628653526306, 'eval_accuracy': 0.8876, 'eval_runtime': 78.8611, 'eval_samples_per_second': 31.701, 'eval_steps_per_second': 1.002, 'epoch': 0.21329541414859582}\n",
            "{'loss': 0.3301, 'grad_norm': 2.385688543319702, 'learning_rate': 2.2534660504799148e-05, 'epoch': 0.24884464984002844}\n",
            "{'eval_loss': 0.33027586340904236, 'eval_accuracy': 0.898, 'eval_runtime': 79.0285, 'eval_samples_per_second': 31.634, 'eval_steps_per_second': 1.0, 'epoch': 0.24884464984002844}\n",
            "{'loss': 0.3099, 'grad_norm': 11.431072235107422, 'learning_rate': 2.1468183434056168e-05, 'epoch': 0.28439388553146105}\n",
            "{'eval_loss': 0.4733218848705292, 'eval_accuracy': 0.8864, 'eval_runtime': 78.562, 'eval_samples_per_second': 31.822, 'eval_steps_per_second': 1.006, 'epoch': 0.28439388553146105}\n",
            "{'loss': 0.3336, 'grad_norm': 9.036660194396973, 'learning_rate': 2.0401706363313188e-05, 'epoch': 0.3199431212228937}\n",
            "{'eval_loss': 0.24896538257598877, 'eval_accuracy': 0.9132, 'eval_runtime': 78.3278, 'eval_samples_per_second': 31.917, 'eval_steps_per_second': 1.009, 'epoch': 0.3199431212228937}\n",
            "{'loss': 0.2857, 'grad_norm': 37.38890838623047, 'learning_rate': 1.933522929257021e-05, 'epoch': 0.35549235691432635}\n",
            "{'eval_loss': 0.3080146312713623, 'eval_accuracy': 0.9116, 'eval_runtime': 78.2463, 'eval_samples_per_second': 31.95, 'eval_steps_per_second': 1.01, 'epoch': 0.35549235691432635}\n",
            "{'loss': 0.2539, 'grad_norm': 0.6151434779167175, 'learning_rate': 1.826875222182723e-05, 'epoch': 0.391041592605759}\n",
            "{'eval_loss': 0.33528271317481995, 'eval_accuracy': 0.9056, 'eval_runtime': 78.8205, 'eval_samples_per_second': 31.718, 'eval_steps_per_second': 1.002, 'epoch': 0.391041592605759}\n",
            "{'loss': 0.2879, 'grad_norm': 1.7705907821655273, 'learning_rate': 1.720227515108425e-05, 'epoch': 0.42659082829719164}\n",
            "{'eval_loss': 0.2716001868247986, 'eval_accuracy': 0.904, 'eval_runtime': 78.8042, 'eval_samples_per_second': 31.724, 'eval_steps_per_second': 1.002, 'epoch': 0.42659082829719164}\n",
            "{'loss': 0.244, 'grad_norm': 17.197816848754883, 'learning_rate': 1.613579808034127e-05, 'epoch': 0.46214006398862423}\n",
            "{'eval_loss': 0.2592061161994934, 'eval_accuracy': 0.9164, 'eval_runtime': 78.7914, 'eval_samples_per_second': 31.729, 'eval_steps_per_second': 1.003, 'epoch': 0.46214006398862423}\n",
            "{'loss': 0.2432, 'grad_norm': 1.839619517326355, 'learning_rate': 1.5069321009598292e-05, 'epoch': 0.4976892996800569}\n",
            "{'eval_loss': 0.3168923556804657, 'eval_accuracy': 0.9192, 'eval_runtime': 78.6337, 'eval_samples_per_second': 31.793, 'eval_steps_per_second': 1.005, 'epoch': 0.4976892996800569}\n",
            "{'loss': 0.3181, 'grad_norm': 17.367753982543945, 'learning_rate': 1.4002843938855315e-05, 'epoch': 0.5332385353714895}\n",
            "{'eval_loss': 0.2573215365409851, 'eval_accuracy': 0.9156, 'eval_runtime': 78.3844, 'eval_samples_per_second': 31.894, 'eval_steps_per_second': 1.008, 'epoch': 0.5332385353714895}\n",
            "{'loss': 0.2067, 'grad_norm': 30.76935577392578, 'learning_rate': 1.2936366868112335e-05, 'epoch': 0.5687877710629221}\n",
            "{'eval_loss': 0.35268881916999817, 'eval_accuracy': 0.918, 'eval_runtime': 78.7082, 'eval_samples_per_second': 31.763, 'eval_steps_per_second': 1.004, 'epoch': 0.5687877710629221}\n",
            "{'loss': 0.2794, 'grad_norm': 4.5922417640686035, 'learning_rate': 1.1869889797369357e-05, 'epoch': 0.6043370067543548}\n",
            "{'eval_loss': 0.3163849711418152, 'eval_accuracy': 0.9228, 'eval_runtime': 78.8456, 'eval_samples_per_second': 31.708, 'eval_steps_per_second': 1.002, 'epoch': 0.6043370067543548}\n",
            "{'loss': 0.2508, 'grad_norm': 10.491552352905273, 'learning_rate': 1.0803412726626379e-05, 'epoch': 0.6398862424457874}\n",
            "{'eval_loss': 0.3037884831428528, 'eval_accuracy': 0.9196, 'eval_runtime': 78.4696, 'eval_samples_per_second': 31.859, 'eval_steps_per_second': 1.007, 'epoch': 0.6398862424457874}\n",
            "{'loss': 0.2842, 'grad_norm': 2.750180959701538, 'learning_rate': 9.736935655883399e-06, 'epoch': 0.67543547813722}\n",
            "{'eval_loss': 0.2706657350063324, 'eval_accuracy': 0.9228, 'eval_runtime': 78.4719, 'eval_samples_per_second': 31.859, 'eval_steps_per_second': 1.007, 'epoch': 0.67543547813722}\n",
            "{'loss': 0.2794, 'grad_norm': 7.900115489959717, 'learning_rate': 8.670458585140419e-06, 'epoch': 0.7109847138286527}\n",
            "{'eval_loss': 0.28584280610084534, 'eval_accuracy': 0.9192, 'eval_runtime': 78.3103, 'eval_samples_per_second': 31.924, 'eval_steps_per_second': 1.009, 'epoch': 0.7109847138286527}\n",
            "{'loss': 0.2524, 'grad_norm': 0.4568521976470947, 'learning_rate': 7.60398151439744e-06, 'epoch': 0.7465339495200853}\n",
            "{'eval_loss': 0.2542608380317688, 'eval_accuracy': 0.9268, 'eval_runtime': 78.9903, 'eval_samples_per_second': 31.649, 'eval_steps_per_second': 1.0, 'epoch': 0.7465339495200853}\n",
            "{'loss': 0.2553, 'grad_norm': 0.2698908746242523, 'learning_rate': 6.5375044436544615e-06, 'epoch': 0.782083185211518}\n",
            "{'eval_loss': 0.2830604910850525, 'eval_accuracy': 0.9212, 'eval_runtime': 78.5944, 'eval_samples_per_second': 31.809, 'eval_steps_per_second': 1.005, 'epoch': 0.782083185211518}\n",
            "{'loss': 0.2533, 'grad_norm': 29.654531478881836, 'learning_rate': 5.471027372911483e-06, 'epoch': 0.8176324209029506}\n",
            "{'eval_loss': 0.2645795941352844, 'eval_accuracy': 0.9216, 'eval_runtime': 78.3845, 'eval_samples_per_second': 31.894, 'eval_steps_per_second': 1.008, 'epoch': 0.8176324209029506}\n",
            "{'loss': 0.2917, 'grad_norm': 2.5760834217071533, 'learning_rate': 4.404550302168503e-06, 'epoch': 0.8531816565943833}\n",
            "{'eval_loss': 0.240645632147789, 'eval_accuracy': 0.9268, 'eval_runtime': 78.3951, 'eval_samples_per_second': 31.89, 'eval_steps_per_second': 1.008, 'epoch': 0.8531816565943833}\n",
            "{'loss': 0.2267, 'grad_norm': 32.46206283569336, 'learning_rate': 3.3380732314255246e-06, 'epoch': 0.8887308922858158}\n",
            "{'eval_loss': 0.2444547861814499, 'eval_accuracy': 0.9284, 'eval_runtime': 78.9809, 'eval_samples_per_second': 31.653, 'eval_steps_per_second': 1.0, 'epoch': 0.8887308922858158}\n",
            "{'loss': 0.2809, 'grad_norm': 0.7792553901672363, 'learning_rate': 2.2715961606825455e-06, 'epoch': 0.9242801279772485}\n",
            "{'eval_loss': 0.24445165693759918, 'eval_accuracy': 0.926, 'eval_runtime': 78.7753, 'eval_samples_per_second': 31.736, 'eval_steps_per_second': 1.003, 'epoch': 0.9242801279772485}\n",
            "{'loss': 0.2223, 'grad_norm': 43.3713493347168, 'learning_rate': 1.2051190899395664e-06, 'epoch': 0.9598293636686811}\n",
            "{'eval_loss': 0.24737651646137238, 'eval_accuracy': 0.928, 'eval_runtime': 78.5304, 'eval_samples_per_second': 31.835, 'eval_steps_per_second': 1.006, 'epoch': 0.9598293636686811}\n",
            "{'loss': 0.2412, 'grad_norm': 1.9213616847991943, 'learning_rate': 1.386420191965873e-07, 'epoch': 0.9953785993601137}\n",
            "{'eval_loss': 0.24657392501831055, 'eval_accuracy': 0.9288, 'eval_runtime': 78.3644, 'eval_samples_per_second': 31.902, 'eval_steps_per_second': 1.008, 'epoch': 0.9953785993601137}\n",
            "{'train_runtime': 4506.7329, 'train_samples_per_second': 4.993, 'train_steps_per_second': 0.624, 'train_loss': 0.2934269491481137, 'epoch': 1.0}\n",
            "{'eval_loss': 0.2444547861814499, 'eval_accuracy': 0.9284, 'eval_runtime': 79.2235, 'eval_samples_per_second': 31.556, 'eval_steps_per_second': 0.997, 'epoch': 1.0}\n",
            "Validation accuracy: 0.9284\n",
            "Best Learning Rate: 3e-05\n",
            "Best Validation Accuracy: 0.9284\n"
          ]
        }
      ],
      "source": [
        "# Your code for hyperparameter optimization here\n",
        "\n",
        "from transformers import AutoModelForSequenceClassification, BertConfig, Trainer, TrainingArguments, EarlyStoppingCallback\n",
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "# Load the accuracy metric to evaluate model performance\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Function to compute accuracy from model predictions\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Convert model outputs (logits) to predicted class labels\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    # Compute accuracy using the accuracy_metric loaded earlier\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Prepare a data collator for dynamic padding of batches\n",
        "# This is necessary to handle sequences of different lengths in a batch\n",
        "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Define the hyperparameter search space\n",
        "# You should manually enter the learning rates you want to explore\n",
        "learning_rates = [1e-5, 3e-5]  # Example learning rates to try\n",
        "# Set a fixed number of epochs for all experiments\n",
        "# You can adjust this value if needed\n",
        "num_train_epochs = 1  # Number of epochs\n",
        "\n",
        "# Function to train and evaluate the model with a given learning rate\n",
        "def objective(learning_rate):\n",
        "    # Define training arguments using the current learning rate\n",
        "    trainer_args = TrainingArguments(\n",
        "        output_dir='checkpoints',             # Directory to save model checkpoints\n",
        "        evaluation_strategy='steps',          # Evaluate model every few steps\n",
        "        logging_strategy='steps',             # Log training progress every few steps\n",
        "        load_best_model_at_end=True,          # Load the best model at the end of training\n",
        "        eval_steps=100,                       # Evaluate every 100 steps\n",
        "        logging_steps=100,                    # Log every 100 steps\n",
        "        learning_rate=learning_rate,          # Current learning rate (hyperparameter being optimized)\n",
        "        per_device_train_batch_size=8,        # Training batch size per GPU/CPU\n",
        "        per_device_eval_batch_size=32,        # Evaluation batch size per GPU/CPU\n",
        "        num_train_epochs=num_train_epochs,    # Fixed number of epochs\n",
        "        metric_for_best_model=\"accuracy\",     # Metric to select the best model\n",
        "        disable_tqdm=True,                    # Disable tqdm progress bar to prevent clutter\n",
        "    )\n",
        "\n",
        "    # Initialize the model with pre-trained weights for sequence classification\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        MODEL_NAME,\n",
        "        config=BertConfig(num_labels=2, id2label=id2label, label2id=label2id)\n",
        "    )\n",
        "\n",
        "    # Set up the Trainer with the model, training arguments, datasets, and evaluation function\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=trainer_args,\n",
        "        train_dataset=train,                  # Training dataset\n",
        "        eval_dataset=val,                     # Validation dataset\n",
        "        compute_metrics=compute_metrics,      # Function to compute accuracy\n",
        "        tokenizer=tokenizer,                  # Tokenizer used for data preprocessing\n",
        "        data_collator=data_collator,          # Data collator for dynamic padding\n",
        "        callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],  # Early stopping callback\n",
        "    )\n",
        "\n",
        "    # Train the model and store the result\n",
        "    trainer.train()\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    eval_result = trainer.evaluate()\n",
        "\n",
        "    # Return the evaluation metric (accuracy) as the result of this training run\n",
        "    return eval_result['eval_accuracy']\n",
        "\n",
        "# Perform a grid search over learning rate values\n",
        "best_accuracy = 0  # Initialize the best accuracy as 0\n",
        "best_learning_rate = None  # Initialize the best learning rate as None\n",
        "\n",
        "# Iterate over each learning rate in the search space\n",
        "for lr in learning_rates:\n",
        "    print(f\"Training with learning_rate={lr}\")\n",
        "    # Train and evaluate the model with the current learning rate\n",
        "    accuracy = objective(lr)\n",
        "    print(f\"Validation accuracy: {accuracy}\")\n",
        "\n",
        "    # Update the best learning rate if the current one is better\n",
        "    if accuracy > best_accuracy:\n",
        "        best_accuracy = accuracy\n",
        "        best_learning_rate = lr\n",
        "\n",
        "# Print out the best learning rate and corresponding validation accuracy\n",
        "print(f\"Best Learning Rate: {best_learning_rate}\")\n",
        "print(f\"Best Validation Accuracy: {best_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EzCYTnfcrvN"
      },
      "source": [
        "### 3.3. Evaluation on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BG7s-yr6crGF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510,
          "referenced_widgets": [
            "abc94426f4d4442983a6438b340d3c03",
            "b9d511e21f82455180cd820cf534179e",
            "1942f064ff4b477b82fe3c53969e3871",
            "d29f64ca08b545f59f5a16fba880915d",
            "23b48cab64c04201a59244a82d0eabad",
            "5b3c5f58b51342a583c8f7d91a0a6aac",
            "7317f2e72a314a47b8ccf31eec61962d",
            "a9f595f525f14e31ac99c08642cf324c",
            "3b2b96a2a9844aca8ed4e6c03e1cc301",
            "a4fd2d5abaf54d4fae1db6aee1694289",
            "a3a0649738434822a22764ddda3ef2f7"
          ]
        },
        "outputId": "8b0a2f07-9841-41c0-c33a-d5387e16171f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-14-52a7b069ef57>:6: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  accuracy_metric = load_metric(\"accuracy\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "abc94426f4d4442983a6438b340d3c03"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The repository for accuracy contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/accuracy.\n",
            "You can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n",
            "\n",
            "Do you wish to run the custom code? [y/N] y\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 1:08:53, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.554200</td>\n",
              "      <td>0.350992</td>\n",
              "      <td>0.863400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.343700</td>\n",
              "      <td>0.323091</td>\n",
              "      <td>0.890520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.347300</td>\n",
              "      <td>0.277700</td>\n",
              "      <td>0.900880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.261700</td>\n",
              "      <td>0.303614</td>\n",
              "      <td>0.904240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.290300</td>\n",
              "      <td>0.247460</td>\n",
              "      <td>0.914320</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=0.3594414825439453, metrics={'train_runtime': 4135.9896, 'train_samples_per_second': 0.967, 'train_steps_per_second': 0.121, 'total_flos': 1052444221440000.0, 'train_loss': 0.3594414825439453, 'epoch': 0.17774617845716317})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Your code to evaluate the final model on the test set here\n",
        "\n",
        "# Your code to train the machine learning model on the training set and evaluate the performance on the validation set here\n",
        "\n",
        "# Define the metric to evaluate model performance\n",
        "accuracy_metric = load_metric(\"accuracy\")\n",
        "\n",
        "# Function to compute metrics from model predictions\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    # Convert logits to predicted class labels\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    # Compute accuracy using the loaded metric\n",
        "    return accuracy_metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# Prepare a data collator for dynamic padding of batches\n",
        "data_collator = transformers.DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "\n",
        "# Set up early stopping to halt training if no improvement is seen for a certain number of evaluations\n",
        "early_stopping_patience = 5\n",
        "early_stopping = transformers.EarlyStoppingCallback(early_stopping_patience)\n",
        "\n",
        "# Define training arguments and configuration\n",
        "trainer_args = transformers.TrainingArguments(\n",
        "    output_dir='checkpoints',                 # Directory to save model checkpoints\n",
        "    evaluation_strategy='steps',              # Evaluate model every few steps\n",
        "    logging_strategy='steps',                 # Log training progress every few steps\n",
        "    load_best_model_at_end=True,              # Load the best model based on validation performance at the end of training\n",
        "    eval_steps=100,                           # Number of steps between evaluations\n",
        "    logging_steps=100,                        # Number of steps between logging\n",
        "    learning_rate=3e-05,                    # Learning rate for the optimizer\n",
        "    per_device_train_batch_size=8,            # Batch size for training\n",
        "    per_device_eval_batch_size=32,            # Batch size for evaluation\n",
        "    max_steps=500,                            # Maximum number of training steps\n",
        ")\n",
        "\n",
        "# Initialize the model for sequence classification with pre-trained weights\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    config=BertConfig(num_labels=2, id2label=id2label, label2id=label2id)\n",
        ")\n",
        "\n",
        "# Set up the Trainer with the model, arguments, datasets, and evaluation function\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    args=trainer_args,\n",
        "    train_dataset=train,\n",
        "    eval_dataset=test,\n",
        "    compute_metrics=compute_metrics,\n",
        "    tokenizer=tokenizer,\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7ylOS8FdYZ5"
      },
      "source": [
        "---\n",
        "\n",
        "## 4. Results and summary\n",
        "\n",
        "### 4.1 Corpus insights\n",
        "\n",
        "In my project, I used the bert-base-uncased model to perform binary sentiment analysis on the IMDb dataset. Through this process, I got insights into both the dataset and the chosen model.\n",
        "\n",
        "The IMDb corpus used for sentiment analysis consists of movie reviews that have been annotated for sentiment, typically as either positive or negative. Each review in the dataset is labeled based on its overall sentiment, providing a binary classification task. The annotations are derived from user ratings and review content, with positive reviews generally corresponding to ratings of 7 or above out of 10, and negative reviews corresponding to ratings of 4 or below. This labeled data is crucial for training and evaluating sentiment analysis models, allowing them to learn to distinguish between positive and negative sentiments based on textual content.\n",
        "\n",
        "The IMDb dataset provides a diverse range of text data, making it ideal for training and evaluating models on sentiment classification tasks. The large volume of reviews in the dataset ensures that the model encounters a variety of language patterns and expressions, which is necessary for robust model performance.\n",
        "\n",
        "The bert-base-uncased model, a variant of BERT, proved to be a suitable choice for this task. Its \"uncased\" nature, which ignores case sensitivity, is particularly useful for sentiment analysis, where the sentiment of a word or phrase is often independent of capitalization. The model's bidirectional mechanism, which considers context from both directions, further contributed to its strong performance in accurately classifying sentiments.\n",
        "\n",
        "Overall, working with the IMDb dataset and the bert-base-uncased model highlighted the importance of leveraging pre-trained models for complex NLP tasks. The model's versatility and strong contextual understanding made it a powerful tool for sentiment analysis, achieving relatively high accuracy in classifying movie reviews.\n",
        "\n",
        "### 4.2 Results\n",
        "\n",
        "After conducting hyperparameter tuning, the model's performance metrics were closely monitored over 500 training steps. The results demonstrate a clear improvement in both training and validation metrics as the tuning progressed:\n",
        "\n",
        "At Step 100, the model showed a training loss of 0.5542 and a validation loss of 0.3510, with an accuracy of 86.34%.\n",
        "By Step 200, the training loss significantly decreased to 0.3437, while the validation loss dropped slightly to 0.3231. The accuracy improved to 89.05%.\n",
        "At Step 300, the training loss marginally increased to 0.3473, but the validation loss saw a notable decrease to 0.2777, boosting accuracy to 90.09%.\n",
        "By Step 400, the training loss further decreased to 0.2617, although the validation loss slightly increased to 0.3036. Despite this, accuracy continued to improve, reaching 90.42%.\n",
        "Finally, at Step 500, the training loss was 0.2903, and the validation loss dropped to its lowest point at 0.2475, resulting in the highest recorded accuracy of 91.43%.\n",
        "\n",
        "These results indicate that the hyperparameter tuning was effective, as the model consistently improved in accuracy while maintaining lower training and validation losses. The final metrics suggest a well-balanced model with strong generalization capabilities for sentiment analysis.\n",
        "\n",
        "### 4.3 Relation to state of the art\n",
        "\n",
        "In my project, I achieved an accuracy of 91.43% using the bert-base-uncased model for binary sentiment analysis on the IMDb dataset. While this is a strong performance, it's important to note that the current state-of-the-art result for this task is 96.68%, achieved by the RoBERTa-large with LlamBERT model. LlamBERT leverages large-scale, low-cost data annotation techniques, which likely contribute to its superior performance. Although bert-base-uncased is a highly effective and widely used model, especially given its accessibility and efficiency, the results from RoBERTa-large with LlamBERT highlight the advancements that can be achieved through the use of more complex models and innovative data annotation methods.\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Bonus Task (optional)\n",
        "\n",
        "### 5.1. Annotating out-of-domain documents\n",
        "\n",
        "(Briefly describe the chosen out-of-domain documents)\n",
        "\n",
        "(Briefly describe the process of annotation)\n",
        "\n",
        "### 5.2 Conversion into dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32DU04FndRdM"
      },
      "outputs": [],
      "source": [
        "# Your code to convert the annotations into a dataset here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ghO4JemeFKK"
      },
      "source": [
        "### 5.3. Model evaluation on out-of-domain test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9tzYWQ_zeCYp"
      },
      "outputs": [],
      "source": [
        "# Your code to evaluate the model on the out-of-domain test set here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XLZlItdePfJ"
      },
      "source": [
        "### 5.4 Bonus task results\n",
        "\n",
        "(Present the results of the evaluation on the out-of-domain test set)\n",
        "\n",
        "### 5.5. Annotated data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L2YJsiIGeYRe"
      },
      "outputs": [],
      "source": [
        "# Include your annotated out-of-domain data here"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "abec4cfcd3594c49b226d9ec86f46d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f28a7101070342839569776cb93b9792",
              "IPY_MODEL_4004f150204e464db1166d7186ad206b",
              "IPY_MODEL_6f23671e01f0482080514e219420de3e"
            ],
            "layout": "IPY_MODEL_e4ec6dbae48f45d2affdd94e0e20f537"
          }
        },
        "f28a7101070342839569776cb93b9792": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb164048af824fa1a43e16a44737bdd2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_babc45c1449f4fdc9a1302b7668ccacc",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡"
          }
        },
        "4004f150204e464db1166d7186ad206b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_488773a845f246228805bdab86a754ac",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8115fc4a046946929b7f70e2e9c5e97f",
            "value": 1652
          }
        },
        "6f23671e01f0482080514e219420de3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_439159668d464fcb8534597dcd6ce4e7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_489ddb48c07d4bf1ac929004d0a93175",
            "value": "â€‡4.21k/?â€‡[00:00&lt;00:00,â€‡264kB/s]"
          }
        },
        "e4ec6dbae48f45d2affdd94e0e20f537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb164048af824fa1a43e16a44737bdd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "babc45c1449f4fdc9a1302b7668ccacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "488773a845f246228805bdab86a754ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8115fc4a046946929b7f70e2e9c5e97f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "439159668d464fcb8534597dcd6ce4e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "489ddb48c07d4bf1ac929004d0a93175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e2def51556034a1599e7f2f89adbd534": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b6884a3d87ba4770abb7ead9288dd36e",
              "IPY_MODEL_876482b203ea456dbbd565b7b39d2e35",
              "IPY_MODEL_bc848861549d47a68fbee496e89a0998"
            ],
            "layout": "IPY_MODEL_ff8f9d056a504a44a78c25af6fa42fa8"
          }
        },
        "b6884a3d87ba4770abb7ead9288dd36e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff10836ee2ef439bb5dbe6d279623d8b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_90ef87fe5d324877bdfe5c35014b1539",
            "value": "Map:â€‡100%"
          }
        },
        "876482b203ea456dbbd565b7b39d2e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_354c266c96d848d79e736022dc5c0cdb",
            "max": 2500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f37228fed04445908f47de9d6a757fbd",
            "value": 2500
          }
        },
        "bc848861549d47a68fbee496e89a0998": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_624b2097c25b44e39f5033852d764c8d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_d067162df7d244e98240db8f934ea10b",
            "value": "â€‡2500/2500â€‡[00:04&lt;00:00,â€‡593.54â€‡examples/s]"
          }
        },
        "ff8f9d056a504a44a78c25af6fa42fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff10836ee2ef439bb5dbe6d279623d8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90ef87fe5d324877bdfe5c35014b1539": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "354c266c96d848d79e736022dc5c0cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f37228fed04445908f47de9d6a757fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "624b2097c25b44e39f5033852d764c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d067162df7d244e98240db8f934ea10b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "abc94426f4d4442983a6438b340d3c03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9d511e21f82455180cd820cf534179e",
              "IPY_MODEL_1942f064ff4b477b82fe3c53969e3871",
              "IPY_MODEL_d29f64ca08b545f59f5a16fba880915d"
            ],
            "layout": "IPY_MODEL_23b48cab64c04201a59244a82d0eabad"
          }
        },
        "b9d511e21f82455180cd820cf534179e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b3c5f58b51342a583c8f7d91a0a6aac",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7317f2e72a314a47b8ccf31eec61962d",
            "value": "Downloadingâ€‡builderâ€‡script:â€‡"
          }
        },
        "1942f064ff4b477b82fe3c53969e3871": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9f595f525f14e31ac99c08642cf324c",
            "max": 1652,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3b2b96a2a9844aca8ed4e6c03e1cc301",
            "value": 1652
          }
        },
        "d29f64ca08b545f59f5a16fba880915d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4fd2d5abaf54d4fae1db6aee1694289",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a3a0649738434822a22764ddda3ef2f7",
            "value": "â€‡4.21k/?â€‡[00:00&lt;00:00,â€‡74.2kB/s]"
          }
        },
        "23b48cab64c04201a59244a82d0eabad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b3c5f58b51342a583c8f7d91a0a6aac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7317f2e72a314a47b8ccf31eec61962d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9f595f525f14e31ac99c08642cf324c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b2b96a2a9844aca8ed4e6c03e1cc301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a4fd2d5abaf54d4fae1db6aee1694289": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3a0649738434822a22764ddda3ef2f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}