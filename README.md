# deep-learning
Title: Building a CNN from Scratch to Achieve Maximum Accuracy with the MNIST Dataset: Training, Evaluation, and Experimental Analysis

Introduction:
The convolutional neural network (CNN) serves as a fundamental architecture for image classification tasks. In this study, we aim to construct a CNN, optimizing its parameters to attain the highest accuracy feasible with the MNIST dataset. Through experimentation, we explore the impact of layer size, depth, activation functions, optimizers, learning rates, batch sizes, and epochs on model performance.

Methodology:
1. Vary the size and depth of inner layers to investigate their effects on accuracy.
2. Experiment with various activation functions such as ReLU, Leaky ReLU, and Sigmoid.
3. Employ different optimizers including SGD, Adam, and RMSprop.
4. Explore the impact of varying learning rates on model accuracy.
5. Investigate the effect of batch size and epochs on training dynamics and final accuracy.
6. Conduct experiments combining various parameters to identify optimal configurations.
