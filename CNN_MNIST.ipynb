{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfSSzOVVr-Eq"
   },
   "source": [
    "**Introduction to Deep Learning\t(TKO_7094)<br> \n",
    "Arvin Jalali<br>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Project Description:*<BR><BR>\n",
    "Build a CNN from scratch and try to achieve the highest possible accuracy with the MNIST dataset.\n",
    "\n",
    "The MNIST data set (https://www.tensorflow.org/datasets/catalog/mnist) is used to train handwritten digit recognition models.\n",
    "This is basically a classification model with 10 classes.\n",
    "\n",
    "Here is a keras / tensorflow example (not CNN) for loading and training a model with MNIST: https://www.tensorflow.org/datasets/keras_example\n",
    "\n",
    "The parameters for training a model can be found at https://keras.io/api/models/model_training_apis/\n",
    "\n",
    "Your tasks:\n",
    "\n",
    "1. Load the MNSIT data set and split into training and test sets.\n",
    "\n",
    "2. Build a CNN with at least one convolutional layer and 2 or more hidden layers and a dense output layer for 10 classes.\n",
    "\n",
    "3. Train your CNN on the MNIST training set (extracted in step 1).\n",
    "\n",
    "4. Evaluate your trained model using the test data set. What is the accuracy of your model?\n",
    "\n",
    "5. Do the following experiments to improve accuracy:\n",
    "    - increase the size and depth of the inner layers, what is the effect on the model accuracy?\n",
    "    - experiment with different activation functions in the inner layers (relu, sigmoid, softmask, etc), see the list of keras activation functions at https://keras.io/api/layers/activations/\n",
    "    - what is the effect of using different activation functions? how about combining the activation function choice with different network size and depth?\n",
    "    - experiment with various optimizers (https://keras.io/api/optimizers/) and learning rate. What is the effect on the resulting model accuracy?\n",
    "    - with all the above variations, experiment with various batch sizes and epochs for training (see https://keras.io/api/models/model_training_apis/)\n",
    "    - what happens if we don't use any CNN layer? (considering the model in https://www.tensorflow.org/datasets/keras_example).\n",
    "\n",
    "6. Write a report on your observations on how the model performed with various experiments in step 5 and submit it along with the colab file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please note that all of my reports are written within this notebook. For each experiment, I have a report written just prior to the corresponding code. Additionally, I provide a summary report at the end of this notebook to enhance its comprehensiveness.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WH6wSlPOkXhn"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0u9-PhB5BhYe",
    "outputId": "20f59f55-4106-4c2b-bea7-3a794aba89bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load MNIST dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalize the pixel values\n",
    "X_train_full = X_train_full / 255.\n",
    "X_test = X_test / 255.\n",
    "\n",
    "# Split into training, validation, and test sets\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Shuffle training data\n",
    "shuffle_index = np.random.permutation(len(X_train))\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 244
    },
    "id": "Vr7aeMI4mRDs",
    "outputId": "f1b0cd62-e950-4d00-bbdc-b2425f7d7968"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x240 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating a grid of images from the MNIST dataset for visualization purposes\n",
    "n_rows = 2\n",
    "n_cols = 10\n",
    "plt.figure(figsize=(n_cols * 1.2, n_rows * 1.2))\n",
    "\n",
    "for row in range(n_rows):\n",
    "    for col in range(n_cols):\n",
    "        index = n_cols * row + col\n",
    "        plt.subplot(n_rows, n_cols, index + 1)\n",
    "        plt.imshow(X_train[index], cmap=\"binary\", interpolation=\"nearest\")\n",
    "        plt.axis('off')\n",
    "        plt.title(str(y_train[index]), fontsize=12)  # Directly accessing label instead of class name\n",
    "\n",
    "plt.subplots_adjust(wspace=0.2, hspace=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "iPzMu6BRpO18"
   },
   "outputs": [],
   "source": [
    "# My functions are here if any\n",
    "\n",
    "# To clear the current Keras session and releasing the resources associated with it\n",
    "def free_memory():\n",
    "  keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Db03RpqCnHC",
    "outputId": "10ffd72c-24b5-4ab5-953b-5c513d2765c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 13, 13, 32)        0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 5, 5, 64)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                102464    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 121930 (476.29 KB)\n",
      "Trainable params: 121930 (476.29 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN as the primary CNN model, and all the future models will be comapred with this!\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5z0miGNlu5Aw"
   },
   "source": [
    "This convolutional neural network (CNN) model is used for image classification tasks. It consists of two convolutional layers, each followed by max-pooling layers for feature extraction and dimensionality reduction. The model begins with a 32-filter convolutional layer, which is then pooled to extract dominant features. This is followed by another convolutional layer with 64 filters, further enhancing feature extraction. After another pooling step, the resulting features are flattened into a 1D vector. A fully connected layer with 64 neurons is employed for further abstraction, before finally reaching the output layer with 10 neurons, representing class probabilities through the softmax activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RWcd9A1loifY",
    "outputId": "f3c41ec2-ca14-408d-a537-060faf865e9c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 4ms/step - loss: 0.1859 - accuracy: 0.9441 - val_loss: 0.0581 - val_accuracy: 0.9832\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0516 - accuracy: 0.9842 - val_loss: 0.0435 - val_accuracy: 0.9868\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0369 - accuracy: 0.9889 - val_loss: 0.0398 - val_accuracy: 0.9892\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0289 - accuracy: 0.9909 - val_loss: 0.0355 - val_accuracy: 0.9896\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0213 - accuracy: 0.9931 - val_loss: 0.0349 - val_accuracy: 0.9902\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0178 - accuracy: 0.9942 - val_loss: 0.0347 - val_accuracy: 0.9900\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0132 - accuracy: 0.9957 - val_loss: 0.0360 - val_accuracy: 0.9898\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0112 - accuracy: 0.9962 - val_loss: 0.0345 - val_accuracy: 0.9922\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0096 - accuracy: 0.9967 - val_loss: 0.0417 - val_accuracy: 0.9906\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0085 - accuracy: 0.9969 - val_loss: 0.0366 - val_accuracy: 0.9902\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0316 - accuracy: 0.9903\n",
      "Test Accuracy: 0.9902999997138977\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w0Q_UtUwvZCy"
   },
   "source": [
    "As we can see, the test accuracy for our primary CNN is 0.9902999997138977 rounded to four digits gives the number 0.9903. This value as test accuracy will be used frequently in future experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Es5WuKR4xyuo"
   },
   "source": [
    "### <font color='red'>Experiment 1: Increase the size and depth of the inner layers, what is the effect on the model accuracy? </font>\n",
    "In this part, I try to change the number of filters and the dimensions of the filters. Also, I try to change the depth by adding some extra layers to the model to see what will happen to the generalization ability of the model on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDH839HUL4U_"
   },
   "source": [
    "In the following code, I increased the number of filters in the first convolutional layer from 32 to 64. Also, I incresed the number of neurons in the fully connected (dense layer) from 64 to 128. As we can see in the following, the test accuracy increased to 0.9923 compared to the test accuracy of our primary model which was 0.9903."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FgIFlKCFajav",
    "outputId": "891c813e-8391-4552-fd6b-d2e7da516a0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.1568 - accuracy: 0.9518 - val_loss: 0.0603 - val_accuracy: 0.9812\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0469 - accuracy: 0.9851 - val_loss: 0.0389 - val_accuracy: 0.9890\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0300 - accuracy: 0.9906 - val_loss: 0.0308 - val_accuracy: 0.9908\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0235 - accuracy: 0.9925 - val_loss: 0.0335 - val_accuracy: 0.9908\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0171 - accuracy: 0.9944 - val_loss: 0.0444 - val_accuracy: 0.9856\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0378 - val_accuracy: 0.9894\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.0333 - val_accuracy: 0.9922\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0085 - accuracy: 0.9971 - val_loss: 0.0407 - val_accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0087 - accuracy: 0.9969 - val_loss: 0.0318 - val_accuracy: 0.9922\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0059 - accuracy: 0.9981 - val_loss: 0.0383 - val_accuracy: 0.9912\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0322 - accuracy: 0.9923\n",
      "Test Accuracy: 0.9922999739646912\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPaDdMFVClDg"
   },
   "source": [
    "The following code is similar to the previous one, with a filter size of 64 for both convolutional layers and 128 neurons for the fully connected layer. However, I increased the dimensions of the filter in both convolutional layers to be 5x5. As we can see, the test accuracy is 0.9915, which is slightly lower than the 0.9923 achieved in the previous experiment, but higher than the test accuracy of the primary model (0.9903).\n",
    "\n",
    "After conducting a little research, I learned that 3x3 filters are commonly used in many CNN architectures for image classification tasks, including those applied to the MNIST dataset. While 5x5 filters are less common for MNIST due to the small size of the images, they can capture slightly larger spatial patterns in the input images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5P-Uecb8gJp",
    "outputId": "8b28117e-38c1-4d02-ef4c-7377b2307601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 6s 5ms/step - loss: 0.1426 - accuracy: 0.9562 - val_loss: 0.0497 - val_accuracy: 0.9842\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0414 - accuracy: 0.9875 - val_loss: 0.0412 - val_accuracy: 0.9882\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0285 - accuracy: 0.9910 - val_loss: 0.0359 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0205 - accuracy: 0.9931 - val_loss: 0.0361 - val_accuracy: 0.9902\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 0.0311 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0136 - accuracy: 0.9957 - val_loss: 0.0328 - val_accuracy: 0.9922\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0112 - accuracy: 0.9967 - val_loss: 0.0364 - val_accuracy: 0.9912\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0086 - accuracy: 0.9972 - val_loss: 0.0335 - val_accuracy: 0.9912\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0362 - val_accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0068 - accuracy: 0.9975 - val_loss: 0.0415 - val_accuracy: 0.9908\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9915\n",
      "Test Accuracy: 0.9915000200271606\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(64, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(5, 5), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcCMAEmbjgGb"
   },
   "source": [
    "In the following code, I enhanced the depth of the CNN model compared to the primary CNN by incorporating an additional convolutional layer with 128 filters, each having dimensions of 3 by 3. As evident from the results, the test accuracy increases to 0.9912, showing a slight improvement over the test accuracy of the primary CNN, which was 0.9903."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X9HSdcjBd0mV",
    "outputId": "18081389-668c-4244-c181-238ed9549b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 6s 5ms/step - loss: 0.1720 - accuracy: 0.9493 - val_loss: 0.0624 - val_accuracy: 0.9824\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0484 - accuracy: 0.9849 - val_loss: 0.0439 - val_accuracy: 0.9864\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0472 - val_accuracy: 0.9888\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0274 - accuracy: 0.9915 - val_loss: 0.0308 - val_accuracy: 0.9904\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0284 - val_accuracy: 0.9934\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0166 - accuracy: 0.9948 - val_loss: 0.0340 - val_accuracy: 0.9908\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.0258 - val_accuracy: 0.9932\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0121 - accuracy: 0.9963 - val_loss: 0.0253 - val_accuracy: 0.9932\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0113 - accuracy: 0.9964 - val_loss: 0.0320 - val_accuracy: 0.9910\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0089 - accuracy: 0.9969 - val_loss: 0.0339 - val_accuracy: 0.9928\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9912\n",
      "Test Accuracy: 0.9911999702453613\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Additional Convolutional Layer 3\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8T2p9zvRkpHT"
   },
   "source": [
    "In the following code, I conducted an experiment with more substantial changes compared to the primary CNN. I simultaneously increased the number of filters in the convolutional layers and the number of neurons in the fully connected layer. Additionally, I added one extra convolutional layer and one extra fully connected layer compared to the primary model.\n",
    "\n",
    "Despite these modifications, the test accuracy achieved is 0.9869, which is slightly lower than the test accuracy of the primary CNN, which was 0.9903."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7oACWfmFNfer",
    "outputId": "8e310ac3-c6da-4a59-e43a-705c50514822"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 7s 6ms/step - loss: 0.2019 - accuracy: 0.9376 - val_loss: 0.0750 - val_accuracy: 0.9786\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0609 - accuracy: 0.9809 - val_loss: 0.0709 - val_accuracy: 0.9808\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.0446 - accuracy: 0.9865 - val_loss: 0.0530 - val_accuracy: 0.9874\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.0315 - accuracy: 0.9905 - val_loss: 0.0509 - val_accuracy: 0.9856\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 6s 7ms/step - loss: 0.0262 - accuracy: 0.9918 - val_loss: 0.0421 - val_accuracy: 0.9900\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0232 - accuracy: 0.9923 - val_loss: 0.0464 - val_accuracy: 0.9880\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0167 - accuracy: 0.9947 - val_loss: 0.0540 - val_accuracy: 0.9864\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.0163 - accuracy: 0.9951 - val_loss: 0.0486 - val_accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.0150 - accuracy: 0.9950 - val_loss: 0.0421 - val_accuracy: 0.9890\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0111 - accuracy: 0.9963 - val_loss: 0.0686 - val_accuracy: 0.9870\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0584 - accuracy: 0.9869\n",
      "Test Accuracy: 0.9868999719619751\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 3\n",
    "    keras.layers.Conv2D(256, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 3\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    # Fully Connected (Dense) Layer 2\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iXIKsaLSQlJC"
   },
   "source": [
    "### <font color='red'>Experiment 2: Try with different activation functions in the inner layers, what is the effect of using different activation functions? how about combining the activation function choice with different network size and depth?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxKnZt3BJCWm"
   },
   "source": [
    "In the following code, I performed an experiment using the sigmoid activation function compared to the primary CNN, which had the ReLU activation function. As seen below, the test accuracy is 0.9881, slightly lower than the test accuracy of the primary CNN, which was 0.9903.\n",
    "\n",
    "After conducting some research on which activation functions yield the highest accuracy for CNNs working on the MNIST dataset, I plan to repeat experiments later using activation functions such as ReLU, ReLU6, and Leaky ReLU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmUMm_QtQDRt",
    "outputId": "52ccd04d-8499-4430-e302-13d37808c601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 4ms/step - loss: 0.9190 - accuracy: 0.7020 - val_loss: 0.2623 - val_accuracy: 0.9318\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.1910 - accuracy: 0.9465 - val_loss: 0.1185 - val_accuracy: 0.9694\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.1108 - accuracy: 0.9686 - val_loss: 0.0862 - val_accuracy: 0.9764\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0817 - accuracy: 0.9761 - val_loss: 0.0664 - val_accuracy: 0.9822\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0644 - accuracy: 0.9813 - val_loss: 0.0642 - val_accuracy: 0.9828\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0540 - accuracy: 0.9840 - val_loss: 0.0591 - val_accuracy: 0.9838\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0458 - accuracy: 0.9861 - val_loss: 0.0493 - val_accuracy: 0.9858\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.0517 - val_accuracy: 0.9852\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0348 - accuracy: 0.9897 - val_loss: 0.0454 - val_accuracy: 0.9868\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0303 - accuracy: 0.9916 - val_loss: 0.0454 - val_accuracy: 0.9864\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9881\n",
      "Test Accuracy: 0.988099992275238\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='sigmoid', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='sigmoid'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='sigmoid'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ecDhhf_YL-wb"
   },
   "source": [
    "In the following code, I conducted an experiment using the softmax activation function in the inner layers of the CNN. As can be seen, the test accuracy decreased considerably to 0.9174 compared to the primary CNN, which had ReLU as the activation function of the inner layers, achieving a test accuracy of 0.9903.\n",
    "\n",
    "Upon further investigation, I discovered that while the softmax activation function is typically utilized in the output layer for multi-class classification, it poses limitations when applied to inner layers of a CNN. In this context, softmax restricts each neuron's output to a range between 0 and 1, potentially hindering the network's ability to effectively distinguish complex features and patterns within the MNIST dataset. Consequently, this constraint may compromise the network's overall learning capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jusJFkM4W38L",
    "outputId": "a1ac7eaa-c8c9-448e-f07c-4bb822d02234"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 6s 5ms/step - loss: 1.9815 - accuracy: 0.3379 - val_loss: 1.3487 - val_accuracy: 0.6116\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 1.0839 - accuracy: 0.6154 - val_loss: 0.9035 - val_accuracy: 0.6232\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.8479 - accuracy: 0.6236 - val_loss: 0.7837 - val_accuracy: 0.6402\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.7666 - accuracy: 0.6403 - val_loss: 0.7335 - val_accuracy: 0.6482\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.7219 - accuracy: 0.6592 - val_loss: 0.6785 - val_accuracy: 0.7508\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.6212 - accuracy: 0.7498 - val_loss: 0.5688 - val_accuracy: 0.7630\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.5443 - accuracy: 0.7733 - val_loss: 0.5123 - val_accuracy: 0.7882\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.4997 - accuracy: 0.7945 - val_loss: 0.4756 - val_accuracy: 0.8144\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.4629 - accuracy: 0.8418 - val_loss: 0.4320 - val_accuracy: 0.8630\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.4067 - accuracy: 0.8716 - val_loss: 0.3579 - val_accuracy: 0.9240\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3725 - accuracy: 0.9174\n",
      "Test Accuracy: 0.9174000024795532\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='softmax', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='softmax'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='softmax'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9KD5zXlJOvr5"
   },
   "source": [
    "In the following code, I used the Leaky ReLU activation function compared to the ReLU activation function in the primary CNN. I achieved a test accuracy of 0.9908, which is a slight improvement compared to the primary CNN with ReLU activation function in the inner layers, which had a test accuracy of 0.9903.\n",
    "\n",
    "After some research, I learned that ReLU sets negative inputs to zero, while Leaky ReLU allows a small, non-zero gradient for negative inputs. This prevents neurons from completely dying out and potentially improves convergence and generalization in deeper networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eADTLFFbZBe5",
    "outputId": "df5a0bc8-5366-43ba-fc85-be2e3113c818"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 6s 5ms/step - loss: 0.1715 - accuracy: 0.9479 - val_loss: 0.0571 - val_accuracy: 0.9822\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0524 - accuracy: 0.9835 - val_loss: 0.0435 - val_accuracy: 0.9870\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0363 - accuracy: 0.9881 - val_loss: 0.0387 - val_accuracy: 0.9896\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0279 - accuracy: 0.9911 - val_loss: 0.0379 - val_accuracy: 0.9898\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0210 - accuracy: 0.9929 - val_loss: 0.0369 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0367 - val_accuracy: 0.9904\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0139 - accuracy: 0.9957 - val_loss: 0.0354 - val_accuracy: 0.9900\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0401 - val_accuracy: 0.9906\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0099 - accuracy: 0.9962 - val_loss: 0.0405 - val_accuracy: 0.9908\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0079 - accuracy: 0.9974 - val_loss: 0.0353 - val_accuracy: 0.9912\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0350 - accuracy: 0.9908\n",
      "Test Accuracy: 0.9908000230789185\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Define Leaky ReLU activation function\n",
    "def leaky_relu(x):\n",
    "    alpha = 0.1  # Define the slope of the negative part\n",
    "    return keras.activations.relu(x, alpha=alpha)\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation=leaky_relu, input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation=leaky_relu),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation=leaky_relu),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OE3yGRhmR73E"
   },
   "source": [
    "In the following code, after a little research, I aimed to enhance the model's generalization ability by adding a couple of Dropout layers and utilizing ReLU activation function in both convolutional and fully connected layers. Surprisingly, I achieved an test accuracy of 0.9922, an improvement compared to the primary model's test accuracy of 0.9903.\n",
    "\n",
    "I found that Dropout layers randomly deactivate a portion of neurons during training, preventing overfitting by promoting robust feature learning. In a CNN on MNIST, they enhance generalization by reducing neuron co-dependency, making the model less sensitive to noise and variations in data, thus improving performance on unseen samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xFophlefefSd",
    "outputId": "6a6ba509-c340-4eaf-d820-8e46fb388c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 7s 6ms/step - loss: 0.2214 - accuracy: 0.9330 - val_loss: 0.0598 - val_accuracy: 0.9822\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0847 - accuracy: 0.9747 - val_loss: 0.0460 - val_accuracy: 0.9876\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0634 - accuracy: 0.9812 - val_loss: 0.0383 - val_accuracy: 0.9894\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0531 - accuracy: 0.9835 - val_loss: 0.0391 - val_accuracy: 0.9892\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0437 - accuracy: 0.9866 - val_loss: 0.0320 - val_accuracy: 0.9918\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0391 - accuracy: 0.9875 - val_loss: 0.0306 - val_accuracy: 0.9924\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0335 - accuracy: 0.9889 - val_loss: 0.0310 - val_accuracy: 0.9920\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0299 - accuracy: 0.9900 - val_loss: 0.0351 - val_accuracy: 0.9908\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0268 - accuracy: 0.9911 - val_loss: 0.0338 - val_accuracy: 0.9902\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0262 - accuracy: 0.9916 - val_loss: 0.0349 - val_accuracy: 0.9926\n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0280 - accuracy: 0.9922\n",
      "Test Accuracy: 0.9922000169754028\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Define the CNN model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjojMkaiT4_L"
   },
   "source": [
    "In the following code, I replicated the previous experiment with a couple of dropout layers, but I introduced an additional (third) convolutional layer, using ReLU activation function in the inner layers. Surprisingly, I achieved an improved test accuracy of 0.9939, which is higher than the 0.9922 obtained in the previous experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "726E3v4yjwWJ",
    "outputId": "fc7c1905-92b9-418b-b89a-6010d9ab4de4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 7s 6ms/step - loss: 0.2590 - accuracy: 0.9209 - val_loss: 0.0512 - val_accuracy: 0.9864\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 6s 7ms/step - loss: 0.0814 - accuracy: 0.9780 - val_loss: 0.0377 - val_accuracy: 0.9898\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0558 - accuracy: 0.9850 - val_loss: 0.0343 - val_accuracy: 0.9912\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 6s 7ms/step - loss: 0.0475 - accuracy: 0.9874 - val_loss: 0.0304 - val_accuracy: 0.9930\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0383 - accuracy: 0.9898 - val_loss: 0.0288 - val_accuracy: 0.9926\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 6s 6ms/step - loss: 0.0342 - accuracy: 0.9911 - val_loss: 0.0328 - val_accuracy: 0.9930\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0287 - accuracy: 0.9920 - val_loss: 0.0331 - val_accuracy: 0.9928\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0259 - accuracy: 0.9928 - val_loss: 0.0433 - val_accuracy: 0.9912\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 6s 7ms/step - loss: 0.0216 - accuracy: 0.9941 - val_loss: 0.0450 - val_accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0215 - accuracy: 0.9941 - val_loss: 0.0332 - val_accuracy: 0.9922\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0215 - accuracy: 0.9939\n",
      "Test Accuracy: 0.9939000010490417\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Define the CNN model\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EITqOqjVBmb"
   },
   "source": [
    "In the following code, I experimented with the ReLU6 activation function as a comparison to the primary CNN, which used the ReLU activation function. I maintained the same size, depth, and inner layers as the primary CNN. The resulting test accuracy was 0.9898, slightly lower than the primary CNN's accuracy of 0.9903.\n",
    "\n",
    "ReLU6, a variation of ReLU activation function commonly employed in neural networks, sets all negative values to zero like ReLU but additionally imposes an upper limit on positive values it generates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oi8weiKFo47U",
    "outputId": "2bdceee7-4898-43e2-d4f5-655f64631004"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 6s 5ms/step - loss: 0.1539 - accuracy: 0.9542 - val_loss: 0.0555 - val_accuracy: 0.9824\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0466 - accuracy: 0.9856 - val_loss: 0.0395 - val_accuracy: 0.9886\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0323 - accuracy: 0.9891 - val_loss: 0.0317 - val_accuracy: 0.9904\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0231 - accuracy: 0.9926 - val_loss: 0.0317 - val_accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0173 - accuracy: 0.9945 - val_loss: 0.0346 - val_accuracy: 0.9912\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0123 - accuracy: 0.9962 - val_loss: 0.0383 - val_accuracy: 0.9886\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0111 - accuracy: 0.9966 - val_loss: 0.0371 - val_accuracy: 0.9906\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0091 - accuracy: 0.9971 - val_loss: 0.0332 - val_accuracy: 0.9916\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0361 - val_accuracy: 0.9914\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0050 - accuracy: 0.9984 - val_loss: 0.0442 - val_accuracy: 0.9910\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0407 - accuracy: 0.9898\n",
      "Test Accuracy: 0.989799976348877\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu6', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu6'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(128, activation='relu6'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZRX2dvHWdwH"
   },
   "source": [
    "### <font color='red'>Experiment 3: Try with various optimizers and learning rate. What is the effect on the resulting model accuracy?</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPXAAnTIaqga"
   },
   "source": [
    "In TensorFlow's Keras API, the default learning rate for the Adam optimizer is indeed 0.001, and the primary CNN utilized the Adam optimizer with the default learning rate. In the following code, I changed the learning rate to 0.01 while still using the Adam optimizer to observe the resulting test accuracy. As shown in the following, the test accuracy decreased to 0.9871, which is a decrease compared to the 0.9903 achieved by the primary CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L0HwjGm4rGzb",
    "outputId": "8644d9f0-bd2c-4897-d861-5e5ea57546e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 4ms/step - loss: 0.1369 - accuracy: 0.9583 - val_loss: 0.0685 - val_accuracy: 0.9820\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0642 - accuracy: 0.9808 - val_loss: 0.0768 - val_accuracy: 0.9774\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.0644 - val_accuracy: 0.9822\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0453 - accuracy: 0.9868 - val_loss: 0.0663 - val_accuracy: 0.9832\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0415 - accuracy: 0.9876 - val_loss: 0.0633 - val_accuracy: 0.9830\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0425 - accuracy: 0.9879 - val_loss: 0.0806 - val_accuracy: 0.9814\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0351 - accuracy: 0.9903 - val_loss: 0.0861 - val_accuracy: 0.9860\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0400 - accuracy: 0.9893 - val_loss: 0.0738 - val_accuracy: 0.9816\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0397 - accuracy: 0.9897 - val_loss: 0.1148 - val_accuracy: 0.9788\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0318 - accuracy: 0.9913 - val_loss: 0.0698 - val_accuracy: 0.9882\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0761 - accuracy: 0.9871\n",
      "Test Accuracy: 0.9871000051498413\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.01)  # Set an appropriate learning rate\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JevPPGsRcgD7"
   },
   "source": [
    "In the following code, I utilized the Adam optimizer with a learning rate of 0.05. The test accuracy decreased significantly to 0.8628, which is quite poor compared to the test accuracy of 0.9903 achieved by the primary CNN using the Adam optimizer with a default learning rate of 0.001.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VOuwbL_Zt2TL",
    "outputId": "8371cdcb-39b0-43af-d497-c8ff6ba00c9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 4ms/step - loss: 0.7217 - accuracy: 0.7718 - val_loss: 0.4848 - val_accuracy: 0.8530\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.5247 - accuracy: 0.8360 - val_loss: 0.4266 - val_accuracy: 0.8620\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.5050 - accuracy: 0.8421 - val_loss: 0.4734 - val_accuracy: 0.8576\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.4878 - accuracy: 0.8473 - val_loss: 0.4716 - val_accuracy: 0.8674\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.4849 - accuracy: 0.8483 - val_loss: 0.4416 - val_accuracy: 0.8680\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.4792 - accuracy: 0.8507 - val_loss: 0.4469 - val_accuracy: 0.8724\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.4778 - accuracy: 0.8505 - val_loss: 0.4915 - val_accuracy: 0.8546\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.4700 - accuracy: 0.8533 - val_loss: 0.4344 - val_accuracy: 0.8590\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.4712 - accuracy: 0.8536 - val_loss: 0.4043 - val_accuracy: 0.8716\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.4714 - accuracy: 0.8532 - val_loss: 0.4294 - val_accuracy: 0.8668\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.4341 - accuracy: 0.8628\n",
      "Test Accuracy: 0.8628000020980835\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.05)  # Set an appropriate learning rate\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN010ewSdqq5"
   },
   "source": [
    "In the following code, I conducted another experiment with a low learning rate of 0.0001 for the Adam optimizer to observe its effect. The test accuracy achieved was 0.9847, which is only slightly less than the 0.9903 achieved by the primary CNN using the Adam optimizer with a default learning rate of 0.001. I expected to observe a considerable change in test accuracy due to the small learning rate, but it did not occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m3-ZTWGju-rF",
    "outputId": "071f75c1-8ae6-4e4c-c454-a03dda23da37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 4ms/step - loss: 0.6123 - accuracy: 0.8341 - val_loss: 0.1979 - val_accuracy: 0.9450\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.1658 - accuracy: 0.9512 - val_loss: 0.1192 - val_accuracy: 0.9682\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.1143 - accuracy: 0.9665 - val_loss: 0.0932 - val_accuracy: 0.9746\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0911 - accuracy: 0.9731 - val_loss: 0.0769 - val_accuracy: 0.9778\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0767 - accuracy: 0.9772 - val_loss: 0.0722 - val_accuracy: 0.9778\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0664 - accuracy: 0.9802 - val_loss: 0.0603 - val_accuracy: 0.9828\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0594 - accuracy: 0.9819 - val_loss: 0.0600 - val_accuracy: 0.9828\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0537 - accuracy: 0.9842 - val_loss: 0.0532 - val_accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0496 - accuracy: 0.9854 - val_loss: 0.0527 - val_accuracy: 0.9848\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0451 - accuracy: 0.9865 - val_loss: 0.0499 - val_accuracy: 0.9866\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0475 - accuracy: 0.9847\n",
      "Test Accuracy: 0.9847000241279602\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.0001)  # Set an appropriate learning rate\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DeMJNls0ey1Q"
   },
   "source": [
    "In the following code, I conducted an experiment using the SGD optimizer with a learning rate of 0.01. The resulting test accuracy is 0.9893."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oPrhRR54w7GC",
    "outputId": "33009b88-6963-4ea3-b5f4-84518ce78d80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.2725 - accuracy: 0.9157 - val_loss: 0.1044 - val_accuracy: 0.9670\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0739 - accuracy: 0.9770 - val_loss: 0.0558 - val_accuracy: 0.9824\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0519 - accuracy: 0.9840 - val_loss: 0.0510 - val_accuracy: 0.9860\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0420 - accuracy: 0.9870 - val_loss: 0.0472 - val_accuracy: 0.9866\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 0.0472 - val_accuracy: 0.9864\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 6s 7ms/step - loss: 0.0284 - accuracy: 0.9908 - val_loss: 0.0432 - val_accuracy: 0.9882\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 6s 7ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.0370 - val_accuracy: 0.9896\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0206 - accuracy: 0.9933 - val_loss: 0.0361 - val_accuracy: 0.9894\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0176 - accuracy: 0.9943 - val_loss: 0.0407 - val_accuracy: 0.9894\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0143 - accuracy: 0.9954 - val_loss: 0.0381 - val_accuracy: 0.9906\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9893\n",
      "Test Accuracy: 0.989300012588501\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "sgd_optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd_optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kEJpyFBefde4"
   },
   "source": [
    "In the following, I conducted an experiment with the SGD optimizer and a high learning rate of 0.5, just to see what happens. As can be seen, the test accuracy is very poor, at 0.1010.\n",
    "\n",
    "The extremely low accuracy of 0.1010 indicates that the model's training became unstable when using the SGD optimizer with a high learning rate of 0.5. This instability suggests that the optimization process overshot the optimal solution, resulting in erratic or incorrect predictions. It emphasizes the necessity of choosing appropriate learning rates and optimizer settings to ensure reliable training and convergence in neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Oy_aEzFASMd3",
    "outputId": "a434a006-bc48-4ea8-f61c-1c11e9430b94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 3.1094 - accuracy: 0.1133 - val_loss: 2.3190 - val_accuracy: 0.1100\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 2.3196 - accuracy: 0.1047 - val_loss: 2.3156 - val_accuracy: 0.1070\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 2.3188 - accuracy: 0.1004 - val_loss: 2.3143 - val_accuracy: 0.1126\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 2.3166 - accuracy: 0.1047 - val_loss: 2.3101 - val_accuracy: 0.1126\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 2.3185 - accuracy: 0.1055 - val_loss: 2.3053 - val_accuracy: 0.0986\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 2.3203 - accuracy: 0.1025 - val_loss: 2.3296 - val_accuracy: 0.0976\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 2.3181 - accuracy: 0.1037 - val_loss: 2.3205 - val_accuracy: 0.1070\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 2.3188 - accuracy: 0.1022 - val_loss: 2.3145 - val_accuracy: 0.0976\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 2.3178 - accuracy: 0.1059 - val_loss: 2.3269 - val_accuracy: 0.0986\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 2.3182 - accuracy: 0.1040 - val_loss: 2.3244 - val_accuracy: 0.0986\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 2.3217 - accuracy: 0.1010\n",
      "Test Accuracy: 0.10100000351667404\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "sgd_optimizer = keras.optimizers.SGD(learning_rate=0.5, momentum=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=sgd_optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D051Yk0vg7MU"
   },
   "source": [
    "In the following code, the RMSprop optimizer with a learning rate of 0.001 was utilized. As can be seen, the test accuracy will be 0.9914, which is considered to be very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8MD2uEYO9T5g",
    "outputId": "7ebaf7c0-6903-46ab-c486-42ead38f5bfc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.1871 - accuracy: 0.9417 - val_loss: 0.0741 - val_accuracy: 0.9826\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0524 - accuracy: 0.9836 - val_loss: 0.0481 - val_accuracy: 0.9852\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0350 - accuracy: 0.9891 - val_loss: 0.0399 - val_accuracy: 0.9886\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0271 - accuracy: 0.9919 - val_loss: 0.0344 - val_accuracy: 0.9906\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0209 - accuracy: 0.9934 - val_loss: 0.0340 - val_accuracy: 0.9898\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0164 - accuracy: 0.9948 - val_loss: 0.0374 - val_accuracy: 0.9908\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0134 - accuracy: 0.9959 - val_loss: 0.0350 - val_accuracy: 0.9908\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0108 - accuracy: 0.9967 - val_loss: 0.0372 - val_accuracy: 0.9920\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0349 - val_accuracy: 0.9926\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0073 - accuracy: 0.9979 - val_loss: 0.0398 - val_accuracy: 0.9916\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0345 - accuracy: 0.9914\n",
      "Test Accuracy: 0.9914000034332275\n"
     ]
    }
   ],
   "source": [
    "free_memory()\n",
    "\n",
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9)\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVm9GBjiX2Ry"
   },
   "source": [
    "### <font color='red'>Experiment 4: With all the above variations, experiment with various batch sizes and epochs for training.</font>\n",
    "In the primary CNN, the number of epochs is set to 10, and the batch size is 64. In the following experiment, I will attempt to vary these parameters to observe their impact on test accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-eu_sU_Zjs6H"
   },
   "source": [
    "In the following code, I conducted an experiment by increasing the batch size to 256 compared to 64 in the primary CNN and the number of epochs is 10 (no change). As can be seen, the test accuracy remains at 0.9904, which is not considerably different from the test accuracy of 0.9903 for the primary CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xIKObM9BY_pD",
    "outputId": "52fcd985-99d7-4d7e-e1fd-e3c54755ac81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "215/215 [==============================] - 3s 7ms/step - loss: 0.3395 - accuracy: 0.9033 - val_loss: 0.1113 - val_accuracy: 0.9686\n",
      "Epoch 2/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0812 - accuracy: 0.9754 - val_loss: 0.0605 - val_accuracy: 0.9832\n",
      "Epoch 3/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0542 - accuracy: 0.9837 - val_loss: 0.0526 - val_accuracy: 0.9848\n",
      "Epoch 4/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0437 - accuracy: 0.9864 - val_loss: 0.0427 - val_accuracy: 0.9896\n",
      "Epoch 5/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0363 - accuracy: 0.9888 - val_loss: 0.0405 - val_accuracy: 0.9882\n",
      "Epoch 6/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0303 - accuracy: 0.9905 - val_loss: 0.0392 - val_accuracy: 0.9898\n",
      "Epoch 7/10\n",
      "215/215 [==============================] - 2s 7ms/step - loss: 0.0259 - accuracy: 0.9922 - val_loss: 0.0396 - val_accuracy: 0.9902\n",
      "Epoch 8/10\n",
      "215/215 [==============================] - 1s 7ms/step - loss: 0.0224 - accuracy: 0.9935 - val_loss: 0.0385 - val_accuracy: 0.9896\n",
      "Epoch 9/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0193 - accuracy: 0.9939 - val_loss: 0.0370 - val_accuracy: 0.9898\n",
      "Epoch 10/10\n",
      "215/215 [==============================] - 1s 6ms/step - loss: 0.0172 - accuracy: 0.9949 - val_loss: 0.0354 - val_accuracy: 0.9910\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0272 - accuracy: 0.9904\n",
      "Test Accuracy: 0.9904000163078308\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=256, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoFDm_S9ko7h"
   },
   "source": [
    "In the following code, I conducted an experiment by increasing the batch size to 1024 (as a very big batch size) compared to 64 in the primary CNN, and the number of epochs remains still 10 as before. As can be seen, the test accuracy will be 0.9872, which is less than the test accuracy of 0.9903 for the primary CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tockLi7uZMaR",
    "outputId": "1109ba70-4892-49f0-d697-8147aef2e128"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "54/54 [==============================] - 2s 19ms/step - loss: 0.8274 - accuracy: 0.7730 - val_loss: 0.2500 - val_accuracy: 0.9286\n",
      "Epoch 2/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1870 - accuracy: 0.9448 - val_loss: 0.1317 - val_accuracy: 0.9606\n",
      "Epoch 3/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.1109 - accuracy: 0.9677 - val_loss: 0.0944 - val_accuracy: 0.9724\n",
      "Epoch 4/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0853 - accuracy: 0.9741 - val_loss: 0.0808 - val_accuracy: 0.9754\n",
      "Epoch 5/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0707 - accuracy: 0.9787 - val_loss: 0.0640 - val_accuracy: 0.9806\n",
      "Epoch 6/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0603 - accuracy: 0.9821 - val_loss: 0.0609 - val_accuracy: 0.9826\n",
      "Epoch 7/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0532 - accuracy: 0.9839 - val_loss: 0.0544 - val_accuracy: 0.9854\n",
      "Epoch 8/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0475 - accuracy: 0.9857 - val_loss: 0.0613 - val_accuracy: 0.9816\n",
      "Epoch 9/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0433 - accuracy: 0.9871 - val_loss: 0.0460 - val_accuracy: 0.9872\n",
      "Epoch 10/10\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0379 - accuracy: 0.9889 - val_loss: 0.0459 - val_accuracy: 0.9874\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0390 - accuracy: 0.9872\n",
      "Test Accuracy: 0.9872000217437744\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=10, batch_size=1024, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_g_8VY4rl60U"
   },
   "source": [
    "In the following code, while keeping the batch size at 64, consistent with the primary CNN, I increased the number of epochs to 40 compared to 10 in the primary CNN. The test accuracy is 0.9914, slightly better than the 0.9903 achieved in the primary CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "84SP7RPgZYKC",
    "outputId": "0023a478-4fc8-42fb-a8de-6900f55fb19f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "860/860 [==============================] - 5s 4ms/step - loss: 0.1898 - accuracy: 0.9436 - val_loss: 0.0651 - val_accuracy: 0.9790\n",
      "Epoch 2/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0570 - accuracy: 0.9821 - val_loss: 0.0463 - val_accuracy: 0.9872\n",
      "Epoch 3/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0403 - accuracy: 0.9873 - val_loss: 0.0426 - val_accuracy: 0.9868\n",
      "Epoch 4/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0315 - accuracy: 0.9899 - val_loss: 0.0335 - val_accuracy: 0.9894\n",
      "Epoch 5/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0246 - accuracy: 0.9922 - val_loss: 0.0344 - val_accuracy: 0.9894\n",
      "Epoch 6/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0179 - accuracy: 0.9940 - val_loss: 0.0351 - val_accuracy: 0.9892\n",
      "Epoch 7/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0376 - val_accuracy: 0.9894\n",
      "Epoch 8/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 0.0341 - val_accuracy: 0.9910\n",
      "Epoch 9/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0091 - accuracy: 0.9970 - val_loss: 0.0464 - val_accuracy: 0.9890\n",
      "Epoch 10/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0086 - accuracy: 0.9973 - val_loss: 0.0381 - val_accuracy: 0.9898\n",
      "Epoch 11/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0088 - accuracy: 0.9971 - val_loss: 0.0588 - val_accuracy: 0.9874\n",
      "Epoch 12/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0061 - accuracy: 0.9981 - val_loss: 0.0315 - val_accuracy: 0.9920\n",
      "Epoch 13/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.0370 - val_accuracy: 0.9906\n",
      "Epoch 14/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0055 - accuracy: 0.9981 - val_loss: 0.0359 - val_accuracy: 0.9916\n",
      "Epoch 15/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0044 - accuracy: 0.9984 - val_loss: 0.0401 - val_accuracy: 0.9906\n",
      "Epoch 16/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0035 - accuracy: 0.9989 - val_loss: 0.0334 - val_accuracy: 0.9924\n",
      "Epoch 17/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0044 - accuracy: 0.9985 - val_loss: 0.0408 - val_accuracy: 0.9918\n",
      "Epoch 18/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0041 - accuracy: 0.9988 - val_loss: 0.0457 - val_accuracy: 0.9900\n",
      "Epoch 19/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0407 - val_accuracy: 0.9918\n",
      "Epoch 20/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0420 - val_accuracy: 0.9924\n",
      "Epoch 21/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0029 - accuracy: 0.9989 - val_loss: 0.0429 - val_accuracy: 0.9906\n",
      "Epoch 22/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0024 - accuracy: 0.9991 - val_loss: 0.0406 - val_accuracy: 0.9910\n",
      "Epoch 23/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0048 - accuracy: 0.9984 - val_loss: 0.0450 - val_accuracy: 0.9918\n",
      "Epoch 24/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0029 - accuracy: 0.9991 - val_loss: 0.0402 - val_accuracy: 0.9916\n",
      "Epoch 25/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0453 - val_accuracy: 0.9894\n",
      "Epoch 26/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0032 - accuracy: 0.9989 - val_loss: 0.0576 - val_accuracy: 0.9898\n",
      "Epoch 27/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0518 - val_accuracy: 0.9910\n",
      "Epoch 28/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0466 - val_accuracy: 0.9916\n",
      "Epoch 29/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0022 - accuracy: 0.9993 - val_loss: 0.0482 - val_accuracy: 0.9920\n",
      "Epoch 30/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0533 - val_accuracy: 0.9908\n",
      "Epoch 31/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.0545 - val_accuracy: 0.9924\n",
      "Epoch 32/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0610 - val_accuracy: 0.9906\n",
      "Epoch 33/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0668 - val_accuracy: 0.9910\n",
      "Epoch 34/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0557 - val_accuracy: 0.9916\n",
      "Epoch 35/40\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.0495 - val_accuracy: 0.9924\n",
      "Epoch 36/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 7.1445e-04 - accuracy: 0.9998 - val_loss: 0.0615 - val_accuracy: 0.9914\n",
      "Epoch 37/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0619 - val_accuracy: 0.9912\n",
      "Epoch 38/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.0764 - val_accuracy: 0.9888\n",
      "Epoch 39/40\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0533 - val_accuracy: 0.9906\n",
      "Epoch 40/40\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0018 - accuracy: 0.9994 - val_loss: 0.0479 - val_accuracy: 0.9910\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0594 - accuracy: 0.9914\n",
      "Test Accuracy: 0.9914000034332275\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=40, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mku-umvdmu2e"
   },
   "source": [
    "In the following code, I conducted another experiment by increasing the batch size from 64 to 128 and the number of epochs from 10 to 20 compared to the primary CNN. The test accuracy is 0.9900, which is slightly less than the 0.9903 achieved in the primary CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbZZOi99aZrf",
    "outputId": "69c216dd-b3f5-4ab5-ee96-cbb37bd7b117"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "430/430 [==============================] - 3s 5ms/step - loss: 0.2622 - accuracy: 0.9213 - val_loss: 0.0715 - val_accuracy: 0.9786\n",
      "Epoch 2/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.9811 - val_loss: 0.0652 - val_accuracy: 0.9792\n",
      "Epoch 3/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0443 - accuracy: 0.9865 - val_loss: 0.0499 - val_accuracy: 0.9862\n",
      "Epoch 4/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.9891 - val_loss: 0.0383 - val_accuracy: 0.9890\n",
      "Epoch 5/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0288 - accuracy: 0.9912 - val_loss: 0.0473 - val_accuracy: 0.9866\n",
      "Epoch 6/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0239 - accuracy: 0.9926 - val_loss: 0.0330 - val_accuracy: 0.9900\n",
      "Epoch 7/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0186 - accuracy: 0.9940 - val_loss: 0.0579 - val_accuracy: 0.9846\n",
      "Epoch 8/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 0.0445 - val_accuracy: 0.9886\n",
      "Epoch 9/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0131 - accuracy: 0.9959 - val_loss: 0.0355 - val_accuracy: 0.9898\n",
      "Epoch 10/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0124 - accuracy: 0.9962 - val_loss: 0.0355 - val_accuracy: 0.9906\n",
      "Epoch 11/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0099 - accuracy: 0.9968 - val_loss: 0.0369 - val_accuracy: 0.9878\n",
      "Epoch 12/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0085 - accuracy: 0.9973 - val_loss: 0.0459 - val_accuracy: 0.9904\n",
      "Epoch 13/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0320 - val_accuracy: 0.9914\n",
      "Epoch 14/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0396 - val_accuracy: 0.9890\n",
      "Epoch 15/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 0.0399 - val_accuracy: 0.9904\n",
      "Epoch 16/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 0.0369 - val_accuracy: 0.9914\n",
      "Epoch 17/20\n",
      "430/430 [==============================] - 2s 5ms/step - loss: 0.0059 - accuracy: 0.9980 - val_loss: 0.0372 - val_accuracy: 0.9904\n",
      "Epoch 18/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0041 - accuracy: 0.9987 - val_loss: 0.0396 - val_accuracy: 0.9912\n",
      "Epoch 19/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0029 - accuracy: 0.9990 - val_loss: 0.0410 - val_accuracy: 0.9908\n",
      "Epoch 20/20\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.0473 - val_accuracy: 0.9890\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0393 - accuracy: 0.9900\n",
      "Test Accuracy: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a CNN\n",
    "model = keras.models.Sequential([\n",
    "    # Convolutional Layer 1\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    # Max Pooling Layer 1\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Convolutional Layer 2\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    # Max Pooling Layer 2\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=20, batch_size=128, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gz0AWImHnZkB"
   },
   "source": [
    "Finally, in the following code, I added an extra convolutional layer and one Dropout layer. I increased the number of neurons in the fully connected layer to 256. The activation function for inner layers is ReLU. I chose the Adam optimizer with a learning rate of 0.001. I selected a batch size of 64 and 15 epochs to observe the test accuracy. The attained test accuracy was 0.9889, falling short of my anticipated improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DvSZ01kKb4DL",
    "outputId": "704e5000-9b62-46fa-e44c-5dd48d6e1280"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "860/860 [==============================] - 12s 6ms/step - loss: 0.2936 - accuracy: 0.9083 - val_loss: 0.0812 - val_accuracy: 0.9772\n",
      "Epoch 2/15\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0924 - accuracy: 0.9726 - val_loss: 0.0668 - val_accuracy: 0.9820\n",
      "Epoch 3/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0650 - accuracy: 0.9805 - val_loss: 0.0580 - val_accuracy: 0.9862\n",
      "Epoch 4/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0511 - accuracy: 0.9846 - val_loss: 0.0478 - val_accuracy: 0.9864\n",
      "Epoch 5/15\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0413 - accuracy: 0.9878 - val_loss: 0.0476 - val_accuracy: 0.9878\n",
      "Epoch 6/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0358 - accuracy: 0.9893 - val_loss: 0.0540 - val_accuracy: 0.9866\n",
      "Epoch 7/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.0450 - val_accuracy: 0.9874\n",
      "Epoch 8/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0267 - accuracy: 0.9920 - val_loss: 0.0407 - val_accuracy: 0.9890\n",
      "Epoch 9/15\n",
      "860/860 [==============================] - 5s 6ms/step - loss: 0.0203 - accuracy: 0.9934 - val_loss: 0.0476 - val_accuracy: 0.9882\n",
      "Epoch 10/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.0487 - val_accuracy: 0.9886\n",
      "Epoch 11/15\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0168 - accuracy: 0.9945 - val_loss: 0.0489 - val_accuracy: 0.9882\n",
      "Epoch 12/15\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.0144 - accuracy: 0.9955 - val_loss: 0.0592 - val_accuracy: 0.9864\n",
      "Epoch 13/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 0.0572 - val_accuracy: 0.9884\n",
      "Epoch 14/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0513 - val_accuracy: 0.9894\n",
      "Epoch 15/15\n",
      "860/860 [==============================] - 4s 5ms/step - loss: 0.0112 - accuracy: 0.9965 - val_loss: 0.0485 - val_accuracy: 0.9888\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0560 - accuracy: 0.9889\n",
      "Test Accuracy: 0.9889000058174133\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Conv2D(128, kernel_size=(3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train.reshape(-1, 28, 28, 1), y_train, epochs=15, batch_size=64, validation_data=(X_valid.reshape(-1, 28, 28, 1), y_valid))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test.reshape(-1, 28, 28, 1), y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tv09xD6pYXQ2"
   },
   "source": [
    "### <font color='red'>Experiment 5: What happens if we don't use any CNN layer?<font>\n",
    "In the following code, a traditional neural network is used instead of a convolutional neural network to observe the impact on test accuracy compared to the primary CNN. As can be seen, the test accuracy is 0.9756, which is lower than the 0.9903 achieved by the primary CNN.\n",
    "\n",
    "After conducting some research and studying, I have learned that the decrease in test accuracy observed when using a traditional neural network instead of a CNN can be attributed to various factors.CNNs effectively capture spatial information through convolutional layers, while traditional networks treat input as a flat vector, leading to the loss of spatial relationships. Moreover, CNNs have fewer parameters and utilize weight sharing, enhancing their parameter efficiency compared to traditional networks. Furthermore, CNNs naturally acquire hierarchical representations of features, facilitating better generalization to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x6XDBJfUsXRp",
    "outputId": "dbc12ba0-9bb1-4676-fea6-cedc8205ab8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "860/860 [==============================] - 4s 3ms/step - loss: 0.3009 - accuracy: 0.9135 - val_loss: 0.1616 - val_accuracy: 0.9518\n",
      "Epoch 2/10\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.1250 - accuracy: 0.9629 - val_loss: 0.1076 - val_accuracy: 0.9668\n",
      "Epoch 3/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0842 - accuracy: 0.9743 - val_loss: 0.0842 - val_accuracy: 0.9736\n",
      "Epoch 4/10\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0642 - accuracy: 0.9801 - val_loss: 0.0728 - val_accuracy: 0.9780\n",
      "Epoch 5/10\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0491 - accuracy: 0.9842 - val_loss: 0.0750 - val_accuracy: 0.9780\n",
      "Epoch 6/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0390 - accuracy: 0.9878 - val_loss: 0.0727 - val_accuracy: 0.9812\n",
      "Epoch 7/10\n",
      "860/860 [==============================] - 4s 4ms/step - loss: 0.0311 - accuracy: 0.9897 - val_loss: 0.0943 - val_accuracy: 0.9732\n",
      "Epoch 8/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0253 - accuracy: 0.9922 - val_loss: 0.0751 - val_accuracy: 0.9782\n",
      "Epoch 9/10\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0217 - accuracy: 0.9932 - val_loss: 0.0755 - val_accuracy: 0.9786\n",
      "Epoch 10/10\n",
      "860/860 [==============================] - 3s 4ms/step - loss: 0.0182 - accuracy: 0.9941 - val_loss: 0.0903 - val_accuracy: 0.9762\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9756\n",
      "Test Accuracy: 0.975600004196167\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Build a traditional neural network\n",
    "model = keras.models.Sequential([\n",
    "    # Flattening Layer\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    # Fully Connected (Dense) Layer 1\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    # Fully Connected (Dense) Layer 2\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    # Output Layer\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Step 3: Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Step 4: Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_valid, y_valid))\n",
    "\n",
    "# Step 5: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FAFooBhEYnUN"
   },
   "source": [
    "# **summary and conclusions**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oMn3AZO64AYu"
   },
   "source": [
    "### 1. Defining the Primary CNN\n",
    "- **Architecture**: Two convolutional layers followed by max-pooling layers for feature extraction and dimensionality reduction.\n",
    "- **Configuration**: Starts with a 32-filter convolutional layer, followed by another layer with 64 filters. Includes a fully connected layer with 64 neurons and an output layer with 10 neurons.\n",
    "- **Activation Functions & Optimization**: Utilizes ReLU activation functions, Adam optimizer, batch size of 64, and 10 epochs.\n",
    "- **Performance**: Achieves a test accuracy of 0.9903.\n",
    "\n",
    "### 2. Experimenting with Size and Depth\n",
    "- **Increasing Depth**: Various experiments increasing the number of filters, dimensions of filters, and depth of layers. Achieves test accuracy up to 0.9939.\n",
    "- **Research Insights**: Reveals the impact of filter size and depth on model accuracy, with 3x3 filters being common in CNN architectures.\n",
    "\n",
    "### 3. Exploring Activation Functions\n",
    "- **Sigmoid & Softmax**: Test accuracies slightly lower than ReLU-based CNN.\n",
    "- **Leaky ReLU & Dropout**: Improves test accuracy, with Leaky ReLU providing a slight boost. Dropout layers enhance generalization.\n",
    "\n",
    "### 4. Optimizers and Learning Rate\n",
    "- **Adam vs. SGD vs. RMSprop**: Adam optimizer with default learning rate yields the best performance. High learning rates degrade performance significantly.\n",
    "- **Impact of Learning Rate**: Varies learning rates with different optimizers to observe effects on test accuracy.\n",
    "\n",
    "### 5. Batch Size and Epochs\n",
    "- **Batch Size & Epochs**: Experimentation with varying batch sizes and epochs. Minor changes observed in test accuracy with adjustments.\n",
    "\n",
    "### 6. Traditional Neural Network Comparison\n",
    "- **CNN vs. Traditional NN**: Traditional NN yields lower test accuracy compared to CNN due to loss of spatial relationships and parameter efficiency of CNNs.\n",
    "\n",
    "By systematically exploring variations in architecture, activation functions, optimizers, learning rates, batch sizes, and epochs, the study provides insights into optimizing CNN models for image classification tasks like the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
